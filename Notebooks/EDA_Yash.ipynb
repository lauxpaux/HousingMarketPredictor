{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">Housing Market Predictor</p> \n",
    "\n",
    "**Start Date:** 2024-03-18  \n",
    "**Authors:**  *Laura Cornejo Paulino * and *Shreyas Chitransh* \n",
    "\n",
    "## Introduciton\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "In this project we explore historical housing data and construct predictive modeling to predict housing prices with the hopes of capturing the decline in the current (2024) housing market. \n",
    "\n",
    "The data can be found in the following [location](https://drive.google.com/file/d/1sNm33rOHkcqPwb1QA_JnLT2VFlOlnPW7/view?usp=drive_link).\n",
    "\n",
    "\n",
    "Once the data is in the appropriate directory we can conduct a big picture exploration of our data. Let's start by loading a few of the important libraries and then look at our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "import numpy as np                      # Working with arrays \n",
    "import pandas as pd                     # Working with Datasets\n",
    "from matplotlib import pyplot as plt    # Creating plots and viewing images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the data with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"data/Real_Estate_Sales_2001-2021_GL.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the data using `.head()` to see the first few rows and guage any insights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>List Year</th>\n",
       "      <th>Date Recorded</th>\n",
       "      <th>Town</th>\n",
       "      <th>Address</th>\n",
       "      <th>Assessed Value</th>\n",
       "      <th>Sale Amount</th>\n",
       "      <th>Sales Ratio</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Residential Type</th>\n",
       "      <th>Non Use Code</th>\n",
       "      <th>Assessor Remarks</th>\n",
       "      <th>OPM remarks</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020348</td>\n",
       "      <td>2020</td>\n",
       "      <td>09/13/2021</td>\n",
       "      <td>Ansonia</td>\n",
       "      <td>230 WAKELEE AVE</td>\n",
       "      <td>150500.0</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>2020</td>\n",
       "      <td>10/02/2020</td>\n",
       "      <td>Ashford</td>\n",
       "      <td>390 TURNPIKE RD</td>\n",
       "      <td>253000.0</td>\n",
       "      <td>430000.0</td>\n",
       "      <td>0.5883</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210317</td>\n",
       "      <td>2021</td>\n",
       "      <td>07/05/2022</td>\n",
       "      <td>Avon</td>\n",
       "      <td>53 COTSWOLD WAY</td>\n",
       "      <td>329730.0</td>\n",
       "      <td>805000.0</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-72.846365959 41.781677018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200212</td>\n",
       "      <td>2020</td>\n",
       "      <td>03/09/2021</td>\n",
       "      <td>Avon</td>\n",
       "      <td>5 CHESTNUT DRIVE</td>\n",
       "      <td>130400.0</td>\n",
       "      <td>179900.0</td>\n",
       "      <td>0.7248</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Condo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200243</td>\n",
       "      <td>2020</td>\n",
       "      <td>04/13/2021</td>\n",
       "      <td>Avon</td>\n",
       "      <td>111 NORTHINGTON DRIVE</td>\n",
       "      <td>619290.0</td>\n",
       "      <td>890000.0</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial Number  List Year Date Recorded     Town                Address  \\\n",
       "0        2020348       2020    09/13/2021  Ansonia        230 WAKELEE AVE   \n",
       "1          20002       2020    10/02/2020  Ashford        390 TURNPIKE RD   \n",
       "2         210317       2021    07/05/2022     Avon        53 COTSWOLD WAY   \n",
       "3         200212       2020    03/09/2021     Avon       5 CHESTNUT DRIVE   \n",
       "4         200243       2020    04/13/2021     Avon  111 NORTHINGTON DRIVE   \n",
       "\n",
       "   Assessed Value  Sale Amount  Sales Ratio Property Type Residential Type  \\\n",
       "0        150500.0     325000.0       0.4630    Commercial              NaN   \n",
       "1        253000.0     430000.0       0.5883   Residential    Single Family   \n",
       "2        329730.0     805000.0       0.4096   Residential    Single Family   \n",
       "3        130400.0     179900.0       0.7248   Residential            Condo   \n",
       "4        619290.0     890000.0       0.6958   Residential    Single Family   \n",
       "\n",
       "  Non Use Code Assessor Remarks OPM remarks  \\\n",
       "0          NaN              NaN         NaN   \n",
       "1          NaN              NaN         NaN   \n",
       "2          NaN              NaN         NaN   \n",
       "3          NaN              NaN         NaN   \n",
       "4          NaN              NaN         NaN   \n",
       "\n",
       "                             Location  \n",
       "0                                 NaN  \n",
       "1                                 NaN  \n",
       "2  POINT (-72.846365959 41.781677018)  \n",
       "3                                 NaN  \n",
       "4                                 NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be specific columns related to:\n",
    "- `Serial Number` (Should be numerical)\n",
    "- `List Year` (May be redundant as we have a Date column)\n",
    "- `Date Recorded` that the listing was recorded (Need to check if it's datetime)\n",
    "- `Town` of the listing (Categorical)\n",
    "- `Address` of the listing (String)\n",
    "- `Assessed Value` of the listing (Float in USD)\n",
    "- `Sale Amount` (Need to check whether it is integer, but should be numerical overall)\n",
    "- `Sales Ratio` (Float of assesed value divided by Sale amount)\n",
    "- `Property Type` (Categorical String)\n",
    "- `Residential Type` (Categorical)\n",
    "- `Non Use Code`  Unsure what the column contains but it has a lot of NaNs\n",
    "- `Assesor Remark` Contains a lot of NaNs and likely string of comments by Assesor\n",
    "- `OPM Remark` Contains a lot of NaN's and likely string of comments by OPM (Find out what OPM is)\n",
    "- `Location` contains some latitude and longitude data but also a lot of NaNs\n",
    "\n",
    "Below we can confirm whether the expected data types match or whether they need to be reset using `.info()` which can give data types, index listings and missing indices in columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1054159 entries, 0 to 1054158\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   Serial Number     1054159 non-null  int64  \n",
      " 1   List Year         1054159 non-null  int64  \n",
      " 2   Date Recorded     1054157 non-null  object \n",
      " 3   Town              1054159 non-null  object \n",
      " 4   Address           1054108 non-null  object \n",
      " 5   Assessed Value    1054159 non-null  float64\n",
      " 6   Sale Amount       1054159 non-null  float64\n",
      " 7   Sales Ratio       1054159 non-null  float64\n",
      " 8   Property Type     671713 non-null   object \n",
      " 9   Residential Type  660275 non-null   object \n",
      " 10  Non Use Code      302242 non-null   object \n",
      " 11  Assessor Remarks  161472 non-null   object \n",
      " 12  OPM remarks       11564 non-null    object \n",
      " 13  Location          254643 non-null   object \n",
      "dtypes: float64(3), int64(2), object(9)\n",
      "memory usage: 112.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Use .info()\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The index seems to be correct and there are 1.054 Million rows of data with 14 columns.\n",
    "- The first 8 columns all seem to have almost all of the data recorded. However we need to ensure that there are no codes or categories in there which relate to `unknown` which is still considered missing information. \n",
    "- The `Date Recorded` needs to be converted to datetime datatype. \n",
    "- A lot of data is missing in:\n",
    "    - `Property Type`;\n",
    "    - `Residential Type`; \n",
    "    - `Non Use Code`;\n",
    "    - `Assesor Remark`; \n",
    "    - `OPM Remark`;\n",
    "    - `Location`.\n",
    "\n",
    "We can check the total number of rows missing for the columns and the exact percentage below that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial Number             0\n",
       "List Year                 0\n",
       "Date Recorded             2\n",
       "Town                      0\n",
       "Address                  51\n",
       "Assessed Value            0\n",
       "Sale Amount               0\n",
       "Sales Ratio               0\n",
       "Property Type        382446\n",
       "Residential Type     393884\n",
       "Non Use Code         751917\n",
       "Assessor Remarks     892687\n",
       "OPM remarks         1042595\n",
       "Location             799516\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at all of the rows with null vales and sum them columnwise\n",
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial Number        0.000000\n",
       "List Year            0.000000\n",
       "Date Recorded        0.000190\n",
       "Town                 0.000000\n",
       "Address              0.004838\n",
       "Assessed Value       0.000000\n",
       "Sale Amount          0.000000\n",
       "Sales Ratio          0.000000\n",
       "Property Type       36.279726\n",
       "Residential Type    37.364762\n",
       "Non Use Code        71.328614\n",
       "Assessor Remarks    84.682387\n",
       "OPM remarks         98.903012\n",
       "Location            75.843967\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide the sum of total null values by the total number of rows to get percentage of null values\n",
    "raw_df.isna().sum()/raw_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 rows of `Date Recorded` missing which is good, as this is a time series problem and we will eventually be turning the Dates into an index after resampling them.   \n",
    "\n",
    "There are 51 addresses missing which we will attempt to impute using other columns if we can.   \n",
    "\n",
    "`Property Type` and `Residential Type` aare bothing missing 36-37% of data and we can check whether the same rows are missing both the pieces of data.  \n",
    "\n",
    "`Non Use Code`, `Assessor Remarks`, `OPM Remarks` and `Location` are all missing over 70% of the data. \n",
    "\n",
    "We will likely not be using these columns anyway (unless we want a non time-series based analysis). Therefore, for now we can drop these columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the discussed columns, inplace so the dataframe doesn't need to be overwritten  \n",
    "# and axis=1 is referring to columns\n",
    "raw_df.drop(['Non Use Code', 'Assessor Remarks', 'OPM remarks', 'Location'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conduct a sanity check below to ensure that the columns indeed got dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1054159 entries, 0 to 1054158\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   Serial Number     1054159 non-null  int64  \n",
      " 1   List Year         1054159 non-null  int64  \n",
      " 2   Date Recorded     1054157 non-null  object \n",
      " 3   Town              1054159 non-null  object \n",
      " 4   Address           1054108 non-null  object \n",
      " 5   Assessed Value    1054159 non-null  float64\n",
      " 6   Sale Amount       1054159 non-null  float64\n",
      " 7   Sales Ratio       1054159 non-null  float64\n",
      " 8   Property Type     671713 non-null   object \n",
      " 9   Residential Type  660275 non-null   object \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 80.4+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are sure that the columns got dropped, we can go ahead and optimise the data set more to our workflow. As a first step we will standardise the column names to include underscore instead of space to make it easier for coding. We will also be converting all the column names to lower case for the same reason. Note that this is a personal choice and not standardised practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a for loop to iterate over all of the columns by calling all the columns from the raw_df\n",
    "for column in raw_df.columns:\n",
    "\n",
    "    # Store a version of the original column name for later use\n",
    "    original_column = column\n",
    "\n",
    "    # For the column name, lower te case and replace space with underscore\n",
    "    column = column.lower().replace(\" \", \"_\")\n",
    "\n",
    "    # Replace the dataframe by renaming the columns by taking original column name saved\n",
    "    # and replacing it with the updated column\n",
    "    raw_df = raw_df.rename(columns={original_column:column})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm the renaming worked for the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1054159 entries, 0 to 1054158\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   serial_number     1054159 non-null  int64  \n",
      " 1   list_year         1054159 non-null  int64  \n",
      " 2   date_recorded     1054157 non-null  object \n",
      " 3   town              1054159 non-null  object \n",
      " 4   address           1054108 non-null  object \n",
      " 5   assessed_value    1054159 non-null  float64\n",
      " 6   sale_amount       1054159 non-null  float64\n",
      " 7   sales_ratio       1054159 non-null  float64\n",
      " 8   property_type     671713 non-null   object \n",
      " 9   residential_type  660275 non-null   object \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 80.4+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the column names are replaced, we can start by checking some of the distributions that can assist us with better understanding the data and may even helo us with imputing missing data. Accordingly we will start with visualising the rows where `address` is missing. We will start by looking at the first 10 rows of data where `address` is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75944</th>\n",
       "      <td>39999</td>\n",
       "      <td>2003</td>\n",
       "      <td>02/02/2004</td>\n",
       "      <td>West Haven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89004</th>\n",
       "      <td>49996</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/17/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101602</th>\n",
       "      <td>48886</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/13/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145969</th>\n",
       "      <td>10537</td>\n",
       "      <td>2001</td>\n",
       "      <td>02/05/2002</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149638</th>\n",
       "      <td>10640</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/19/2001</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>46.800444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234863</th>\n",
       "      <td>20280</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236356</th>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263008</th>\n",
       "      <td>30125</td>\n",
       "      <td>2003</td>\n",
       "      <td>11/10/2003</td>\n",
       "      <td>New Milford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55090.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.137725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276118</th>\n",
       "      <td>39998</td>\n",
       "      <td>2003</td>\n",
       "      <td>08/12/2004</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284788</th>\n",
       "      <td>30100</td>\n",
       "      <td>2003</td>\n",
       "      <td>05/20/2004</td>\n",
       "      <td>North Stonington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7210.0</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>0.048389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289386</th>\n",
       "      <td>39995</td>\n",
       "      <td>2003</td>\n",
       "      <td>02/02/2004</td>\n",
       "      <td>West Haven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296156</th>\n",
       "      <td>39998</td>\n",
       "      <td>2003</td>\n",
       "      <td>02/20/2004</td>\n",
       "      <td>West Haven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296748</th>\n",
       "      <td>40088</td>\n",
       "      <td>2004</td>\n",
       "      <td>11/01/2004</td>\n",
       "      <td>Groton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7060035.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297284</th>\n",
       "      <td>48889</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/02/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310485</th>\n",
       "      <td>40080</td>\n",
       "      <td>2004</td>\n",
       "      <td>11/24/2004</td>\n",
       "      <td>Brookfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147340.0</td>\n",
       "      <td>1015000.0</td>\n",
       "      <td>0.145163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313376</th>\n",
       "      <td>39997</td>\n",
       "      <td>2003</td>\n",
       "      <td>02/02/2004</td>\n",
       "      <td>West Haven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315350</th>\n",
       "      <td>48888</td>\n",
       "      <td>2004</td>\n",
       "      <td>03/03/2005</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319336</th>\n",
       "      <td>49999</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/12/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329404</th>\n",
       "      <td>48887</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/30/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330019</th>\n",
       "      <td>40070</td>\n",
       "      <td>2004</td>\n",
       "      <td>10/12/2004</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54950.0</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331974</th>\n",
       "      <td>40059</td>\n",
       "      <td>2004</td>\n",
       "      <td>04/29/2005</td>\n",
       "      <td>Harwinton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334893</th>\n",
       "      <td>48884</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/13/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338946</th>\n",
       "      <td>48885</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/13/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340556</th>\n",
       "      <td>49997</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/27/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341747</th>\n",
       "      <td>49994</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/12/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342559</th>\n",
       "      <td>48811</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/22/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344259</th>\n",
       "      <td>48810</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/02/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344747</th>\n",
       "      <td>49993</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/23/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344819</th>\n",
       "      <td>40318</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/07/2005</td>\n",
       "      <td>East Hampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345481</th>\n",
       "      <td>48888</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/08/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345865</th>\n",
       "      <td>49998</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/12/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346288</th>\n",
       "      <td>41588</td>\n",
       "      <td>2004</td>\n",
       "      <td>09/20/2005</td>\n",
       "      <td>Meriden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348686</th>\n",
       "      <td>49995</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/12/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365828</th>\n",
       "      <td>49999</td>\n",
       "      <td>2004</td>\n",
       "      <td>07/05/2005</td>\n",
       "      <td>Salem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367924</th>\n",
       "      <td>49998</td>\n",
       "      <td>2004</td>\n",
       "      <td>07/05/2005</td>\n",
       "      <td>Salem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368474</th>\n",
       "      <td>41230</td>\n",
       "      <td>2004</td>\n",
       "      <td>03/10/2005</td>\n",
       "      <td>Waterbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234500.0</td>\n",
       "      <td>425000.0</td>\n",
       "      <td>0.551765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370597</th>\n",
       "      <td>48992</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/12/2005</td>\n",
       "      <td>Salem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372066</th>\n",
       "      <td>40198</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/02/2005</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50200.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>0.143429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374438</th>\n",
       "      <td>49997</td>\n",
       "      <td>2004</td>\n",
       "      <td>07/08/2005</td>\n",
       "      <td>Salem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391119</th>\n",
       "      <td>40285</td>\n",
       "      <td>2004</td>\n",
       "      <td>01/11/2005</td>\n",
       "      <td>Torrington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155800.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396853</th>\n",
       "      <td>50862</td>\n",
       "      <td>2005</td>\n",
       "      <td>05/16/2006</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104100.0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>0.671613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462293</th>\n",
       "      <td>60058</td>\n",
       "      <td>2006</td>\n",
       "      <td>09/17/2007</td>\n",
       "      <td>Lyme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3656.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466717</th>\n",
       "      <td>60474</td>\n",
       "      <td>2006</td>\n",
       "      <td>07/30/2007</td>\n",
       "      <td>Farmington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>453369.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>Single Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471408</th>\n",
       "      <td>60054</td>\n",
       "      <td>2006</td>\n",
       "      <td>12/08/2006</td>\n",
       "      <td>New Fairfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471587</th>\n",
       "      <td>60032</td>\n",
       "      <td>2006</td>\n",
       "      <td>02/21/2007</td>\n",
       "      <td>Sterling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181310.0</td>\n",
       "      <td>301500.0</td>\n",
       "      <td>0.601360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471622</th>\n",
       "      <td>60159</td>\n",
       "      <td>2006</td>\n",
       "      <td>08/21/2007</td>\n",
       "      <td>Litchfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55190.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0.919833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480138</th>\n",
       "      <td>60043</td>\n",
       "      <td>2006</td>\n",
       "      <td>07/19/2007</td>\n",
       "      <td>Pomfret</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445340.0</td>\n",
       "      <td>875000.0</td>\n",
       "      <td>0.508960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499599</th>\n",
       "      <td>60237</td>\n",
       "      <td>2006</td>\n",
       "      <td>04/02/2007</td>\n",
       "      <td>South Windsor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72340.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.321511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918926</th>\n",
       "      <td>170165</td>\n",
       "      <td>2017</td>\n",
       "      <td>12/08/2017</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129300.0</td>\n",
       "      <td>224000.0</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>Two Family</td>\n",
       "      <td>Two Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948271</th>\n",
       "      <td>172767</td>\n",
       "      <td>2017</td>\n",
       "      <td>01/12/2018</td>\n",
       "      <td>Shelton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227500.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>Condo</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        serial_number  list_year date_recorded              town address  \\\n",
       "75944           39999       2003    02/02/2004        West Haven     NaN   \n",
       "89004           49996       2004    05/17/2005            Lisbon     NaN   \n",
       "101602          48886       2004    06/13/2005            Lisbon     NaN   \n",
       "145969          10537       2001    02/05/2002          Hartford     NaN   \n",
       "149638          10640       2001    12/19/2001        Bridgeport     NaN   \n",
       "234863          20280       2002           NaN            Orange     NaN   \n",
       "236356              0       2002           NaN            Orange     NaN   \n",
       "263008          30125       2003    11/10/2003       New Milford     NaN   \n",
       "276118          39998       2003    08/12/2004            Lisbon     NaN   \n",
       "284788          30100       2003    05/20/2004  North Stonington     NaN   \n",
       "289386          39995       2003    02/02/2004        West Haven     NaN   \n",
       "296156          39998       2003    02/20/2004        West Haven     NaN   \n",
       "296748          40088       2004    11/01/2004            Groton     NaN   \n",
       "297284          48889       2004    06/02/2005            Lisbon     NaN   \n",
       "310485          40080       2004    11/24/2004        Brookfield     NaN   \n",
       "313376          39997       2003    02/02/2004        West Haven     NaN   \n",
       "315350          48888       2004    03/03/2005        Bridgeport     NaN   \n",
       "319336          49999       2004    05/12/2005            Lisbon     NaN   \n",
       "329404          48887       2004    06/30/2005            Lisbon     NaN   \n",
       "330019          40070       2004    10/12/2004          Hartford     NaN   \n",
       "331974          40059       2004    04/29/2005         Harwinton     NaN   \n",
       "334893          48884       2004    05/13/2005            Lisbon     NaN   \n",
       "338946          48885       2004    05/13/2005            Lisbon     NaN   \n",
       "340556          49997       2004    05/27/2005            Lisbon     NaN   \n",
       "341747          49994       2004    05/12/2005            Lisbon     NaN   \n",
       "342559          48811       2004    06/22/2005            Lisbon     NaN   \n",
       "344259          48810       2004    06/02/2005            Lisbon     NaN   \n",
       "344747          49993       2004    05/23/2005            Lisbon     NaN   \n",
       "344819          40318       2004    06/07/2005      East Hampton     NaN   \n",
       "345481          48888       2004    06/08/2005            Lisbon     NaN   \n",
       "345865          49998       2004    05/12/2005            Lisbon     NaN   \n",
       "346288          41588       2004    09/20/2005           Meriden     NaN   \n",
       "348686          49995       2004    05/12/2005            Lisbon     NaN   \n",
       "365828          49999       2004    07/05/2005             Salem     NaN   \n",
       "367924          49998       2004    07/05/2005             Salem     NaN   \n",
       "368474          41230       2004    03/10/2005         Waterbury     NaN   \n",
       "370597          48992       2004    05/12/2005             Salem     NaN   \n",
       "372066          40198       2004    06/02/2005           Norfolk     NaN   \n",
       "374438          49997       2004    07/08/2005             Salem     NaN   \n",
       "391119          40285       2004    01/11/2005        Torrington     NaN   \n",
       "396853          50862       2005    05/16/2006           Bristol     NaN   \n",
       "462293          60058       2006    09/17/2007              Lyme     NaN   \n",
       "466717          60474       2006    07/30/2007        Farmington     NaN   \n",
       "471408          60054       2006    12/08/2006     New Fairfield     NaN   \n",
       "471587          60032       2006    02/21/2007          Sterling     NaN   \n",
       "471622          60159       2006    08/21/2007        Litchfield     NaN   \n",
       "480138          60043       2006    07/19/2007           Pomfret     NaN   \n",
       "499599          60237       2006    04/02/2007     South Windsor     NaN   \n",
       "918926         170165       2017    12/08/2017        Manchester     NaN   \n",
       "948271         172767       2017    01/12/2018           Shelton     NaN   \n",
       "\n",
       "        assessed_value  sale_amount  sales_ratio  property_type  \\\n",
       "75944              0.0          0.0     0.000000            NaN   \n",
       "89004              0.0          0.0     0.000000            NaN   \n",
       "101602             0.0          0.0     0.000000            NaN   \n",
       "145969             0.0     120000.0     0.000000            NaN   \n",
       "149638       2106020.0      45000.0    46.800444            NaN   \n",
       "234863             0.0          0.0     0.000000            NaN   \n",
       "236356             0.0          0.0     0.000000            NaN   \n",
       "263008         55090.0     400000.0     0.137725            NaN   \n",
       "276118             0.0          0.0     0.000000            NaN   \n",
       "284788          7210.0     149000.0     0.048389            NaN   \n",
       "289386             0.0          0.0     0.000000            NaN   \n",
       "296156             0.0          0.0     0.000000            NaN   \n",
       "296748             0.0    7060035.0     0.000000            NaN   \n",
       "297284             0.0          0.0     0.000000            NaN   \n",
       "310485        147340.0    1015000.0     0.145163            NaN   \n",
       "313376             0.0          0.0     0.000000            NaN   \n",
       "315350             0.0          0.0     0.000000            NaN   \n",
       "319336             0.0          0.0     0.000000            NaN   \n",
       "329404             0.0          0.0     0.000000            NaN   \n",
       "330019         54950.0     105000.0     0.523333            NaN   \n",
       "331974             0.0     450000.0     0.000000            NaN   \n",
       "334893             0.0          0.0     0.000000            NaN   \n",
       "338946             0.0          0.0     0.000000            NaN   \n",
       "340556             0.0          0.0     0.000000            NaN   \n",
       "341747             0.0          0.0     0.000000            NaN   \n",
       "342559             0.0          0.0     0.000000            NaN   \n",
       "344259             0.0          0.0     0.000000            NaN   \n",
       "344747             0.0          0.0     0.000000            NaN   \n",
       "344819             0.0     400000.0     0.000000            NaN   \n",
       "345481             0.0          0.0     0.000000            NaN   \n",
       "345865             0.0          0.0     0.000000            NaN   \n",
       "346288             0.0        100.0     0.000000            NaN   \n",
       "348686             0.0          0.0     0.000000            NaN   \n",
       "365828             0.0          0.0     0.000000            NaN   \n",
       "367924             0.0          0.0     0.000000            NaN   \n",
       "368474        234500.0     425000.0     0.551765            NaN   \n",
       "370597             0.0          0.0     0.000000            NaN   \n",
       "372066         50200.0     350000.0     0.143429            NaN   \n",
       "374438             0.0          0.0     0.000000            NaN   \n",
       "391119             0.0     155800.0     0.000000            NaN   \n",
       "396853        104100.0     155000.0     0.671613            NaN   \n",
       "462293             0.0       3656.0     0.000000            NaN   \n",
       "466717             0.0     453369.0     0.000000  Single Family   \n",
       "471408             0.0       3500.0     0.000000            NaN   \n",
       "471587        181310.0     301500.0     0.601360            NaN   \n",
       "471622         55190.0      60000.0     0.919833            NaN   \n",
       "480138        445340.0     875000.0     0.508960            NaN   \n",
       "499599         72340.0     225000.0     0.321511            NaN   \n",
       "918926        129300.0     224000.0     0.577200     Two Family   \n",
       "948271        227500.0     500000.0     0.455000          Condo   \n",
       "\n",
       "       residential_type  \n",
       "75944               NaN  \n",
       "89004               NaN  \n",
       "101602              NaN  \n",
       "145969              NaN  \n",
       "149638              NaN  \n",
       "234863              NaN  \n",
       "236356              NaN  \n",
       "263008              NaN  \n",
       "276118              NaN  \n",
       "284788              NaN  \n",
       "289386              NaN  \n",
       "296156              NaN  \n",
       "296748              NaN  \n",
       "297284              NaN  \n",
       "310485              NaN  \n",
       "313376              NaN  \n",
       "315350              NaN  \n",
       "319336              NaN  \n",
       "329404              NaN  \n",
       "330019              NaN  \n",
       "331974              NaN  \n",
       "334893              NaN  \n",
       "338946              NaN  \n",
       "340556              NaN  \n",
       "341747              NaN  \n",
       "342559              NaN  \n",
       "344259              NaN  \n",
       "344747              NaN  \n",
       "344819              NaN  \n",
       "345481              NaN  \n",
       "345865              NaN  \n",
       "346288              NaN  \n",
       "348686              NaN  \n",
       "365828              NaN  \n",
       "367924              NaN  \n",
       "368474              NaN  \n",
       "370597              NaN  \n",
       "372066              NaN  \n",
       "374438              NaN  \n",
       "391119              NaN  \n",
       "396853              NaN  \n",
       "462293              NaN  \n",
       "466717    Single Family  \n",
       "471408              NaN  \n",
       "471587              NaN  \n",
       "471622              NaN  \n",
       "480138              NaN  \n",
       "499599              NaN  \n",
       "918926       Two Family  \n",
       "948271            Condo  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[raw_df['address'].isna()].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has provided a lot of interesting insights immedietely. \n",
    "1. The 2 rows of missing `date_recorded` are also coinciding with missing address. \n",
    "2. There are a lot of listings where the `assessed_value` and/or `sale_amount` (and therefore `sales_ratio`) are 0. This is important to note as these values would be used in our data for the time series modeling.\n",
    "3. The dates of these listings with missing addresses are mostly quite old, around 2004-2007 which works better for our modeling as we will then have cleaner data for dates nearer to our target years of early 2020's.\n",
    "\n",
    "We can actually drop the address column too as it won't be used for the time series analysis, but as part of this workflow, we can also create a cleaner overall dataset that can potentially be used for other modelling aspects. For now, as there is no way to impute the addresses and the NaN addresses coincide with other missing information, we will drop the rows where both the `address` and `assessed_value` and/or `sale_amount` are missing. \n",
    "\n",
    "This will be achieved by checking all of the rows where `address` is missing and `sales_ratio` is 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows where address is null and sales_ratio is 0\n",
    "len(raw_df[(raw_df['address'].isna()) & (raw_df['sales_ratio']==0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total there are 36 rows of data with null `address` and `sales_ratio` of 0. We can drop these rows. We will also reset the index to make sure they fall in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the row indexes where the address is null and sales_ratio is 0. Reset the index after. \n",
    "raw_df = raw_df.drop(raw_df[(raw_df['address'].isna()) & (raw_df['sales_ratio']==0)].index, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm this has worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1054123 entries, 0 to 1054122\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   serial_number     1054123 non-null  int64  \n",
      " 1   list_year         1054123 non-null  int64  \n",
      " 2   date_recorded     1054123 non-null  object \n",
      " 3   town              1054123 non-null  object \n",
      " 4   address           1054108 non-null  object \n",
      " 5   assessed_value    1054123 non-null  float64\n",
      " 6   sale_amount       1054123 non-null  float64\n",
      " 7   sales_ratio       1054123 non-null  float64\n",
      " 8   property_type     671712 non-null   object \n",
      " 9   residential_type  660274 non-null   object \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 80.4+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the total missing data rows again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "serial_number            0\n",
       "list_year                0\n",
       "date_recorded            0\n",
       "town                     0\n",
       "address                 15\n",
       "assessed_value           0\n",
       "sale_amount              0\n",
       "sales_ratio              0\n",
       "property_type       382411\n",
       "residential_type    393849\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at all of the rows with null vales and sum them columnwise\n",
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are another 15 rows of addresses missing. Let's explore them. <a id='missing_addresses'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149634</th>\n",
       "      <td>10640</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/19/2001</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>46.800444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263002</th>\n",
       "      <td>30125</td>\n",
       "      <td>2003</td>\n",
       "      <td>11/10/2003</td>\n",
       "      <td>New Milford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55090.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.137725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284781</th>\n",
       "      <td>30100</td>\n",
       "      <td>2003</td>\n",
       "      <td>05/20/2004</td>\n",
       "      <td>North Stonington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7210.0</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>0.048389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310474</th>\n",
       "      <td>40080</td>\n",
       "      <td>2004</td>\n",
       "      <td>11/24/2004</td>\n",
       "      <td>Brookfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147340.0</td>\n",
       "      <td>1015000.0</td>\n",
       "      <td>0.145163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330004</th>\n",
       "      <td>40070</td>\n",
       "      <td>2004</td>\n",
       "      <td>10/12/2004</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54950.0</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368444</th>\n",
       "      <td>41230</td>\n",
       "      <td>2004</td>\n",
       "      <td>03/10/2005</td>\n",
       "      <td>Waterbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234500.0</td>\n",
       "      <td>425000.0</td>\n",
       "      <td>0.551765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372035</th>\n",
       "      <td>40198</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/02/2005</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50200.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>0.143429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396820</th>\n",
       "      <td>50862</td>\n",
       "      <td>2005</td>\n",
       "      <td>05/16/2006</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104100.0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>0.671613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471551</th>\n",
       "      <td>60032</td>\n",
       "      <td>2006</td>\n",
       "      <td>02/21/2007</td>\n",
       "      <td>Sterling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181310.0</td>\n",
       "      <td>301500.0</td>\n",
       "      <td>0.601360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471586</th>\n",
       "      <td>60159</td>\n",
       "      <td>2006</td>\n",
       "      <td>08/21/2007</td>\n",
       "      <td>Litchfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55190.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0.919833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480102</th>\n",
       "      <td>60043</td>\n",
       "      <td>2006</td>\n",
       "      <td>07/19/2007</td>\n",
       "      <td>Pomfret</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445340.0</td>\n",
       "      <td>875000.0</td>\n",
       "      <td>0.508960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499563</th>\n",
       "      <td>60237</td>\n",
       "      <td>2006</td>\n",
       "      <td>04/02/2007</td>\n",
       "      <td>South Windsor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72340.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.321511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918890</th>\n",
       "      <td>170165</td>\n",
       "      <td>2017</td>\n",
       "      <td>12/08/2017</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129300.0</td>\n",
       "      <td>224000.0</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>Two Family</td>\n",
       "      <td>Two Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948235</th>\n",
       "      <td>172767</td>\n",
       "      <td>2017</td>\n",
       "      <td>01/12/2018</td>\n",
       "      <td>Shelton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227500.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>Condo</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952051</th>\n",
       "      <td>17001</td>\n",
       "      <td>2017</td>\n",
       "      <td>10/02/2017</td>\n",
       "      <td>North Haven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193130.0</td>\n",
       "      <td>242000.0</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>Single Family</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        serial_number  list_year date_recorded              town address  \\\n",
       "149634          10640       2001    12/19/2001        Bridgeport     NaN   \n",
       "263002          30125       2003    11/10/2003       New Milford     NaN   \n",
       "284781          30100       2003    05/20/2004  North Stonington     NaN   \n",
       "310474          40080       2004    11/24/2004        Brookfield     NaN   \n",
       "330004          40070       2004    10/12/2004          Hartford     NaN   \n",
       "368444          41230       2004    03/10/2005         Waterbury     NaN   \n",
       "372035          40198       2004    06/02/2005           Norfolk     NaN   \n",
       "396820          50862       2005    05/16/2006           Bristol     NaN   \n",
       "471551          60032       2006    02/21/2007          Sterling     NaN   \n",
       "471586          60159       2006    08/21/2007        Litchfield     NaN   \n",
       "480102          60043       2006    07/19/2007           Pomfret     NaN   \n",
       "499563          60237       2006    04/02/2007     South Windsor     NaN   \n",
       "918890         170165       2017    12/08/2017        Manchester     NaN   \n",
       "948235         172767       2017    01/12/2018           Shelton     NaN   \n",
       "952051          17001       2017    10/02/2017       North Haven     NaN   \n",
       "\n",
       "        assessed_value  sale_amount  sales_ratio  property_type  \\\n",
       "149634       2106020.0      45000.0    46.800444            NaN   \n",
       "263002         55090.0     400000.0     0.137725            NaN   \n",
       "284781          7210.0     149000.0     0.048389            NaN   \n",
       "310474        147340.0    1015000.0     0.145163            NaN   \n",
       "330004         54950.0     105000.0     0.523333            NaN   \n",
       "368444        234500.0     425000.0     0.551765            NaN   \n",
       "372035         50200.0     350000.0     0.143429            NaN   \n",
       "396820        104100.0     155000.0     0.671613            NaN   \n",
       "471551        181310.0     301500.0     0.601360            NaN   \n",
       "471586         55190.0      60000.0     0.919833            NaN   \n",
       "480102        445340.0     875000.0     0.508960            NaN   \n",
       "499563         72340.0     225000.0     0.321511            NaN   \n",
       "918890        129300.0     224000.0     0.577200     Two Family   \n",
       "948235        227500.0     500000.0     0.455000          Condo   \n",
       "952051        193130.0     242000.0     0.798000  Single Family   \n",
       "\n",
       "       residential_type  \n",
       "149634              NaN  \n",
       "263002              NaN  \n",
       "284781              NaN  \n",
       "310474              NaN  \n",
       "330004              NaN  \n",
       "368444              NaN  \n",
       "372035              NaN  \n",
       "396820              NaN  \n",
       "471551              NaN  \n",
       "471586              NaN  \n",
       "480102              NaN  \n",
       "499563              NaN  \n",
       "918890       Two Family  \n",
       "948235            Condo  \n",
       "952051    Single Family  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[raw_df['address'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can append the indexes of the missing addresses in a list to use it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149634, 263002, 284781, 310474, 330004, 368444, 372035, 396820, 471551, 471586, 480102, 499563, 918890, 948235, 952051]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the addresses\n",
    "missing_address_list = []\n",
    "\n",
    "# For each index in the missing address lisst\n",
    "for add in raw_df[raw_df['address'].isna()].index:\n",
    "\n",
    "    # Add the index to the list\n",
    "    missing_address_list.append(add)\n",
    "\n",
    "# Sanity Check to see this worked\n",
    "print(missing_address_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these remaining missing `addresses`, we can see what type of addresses are present based on the town. May be narrowing down the town with approximate prices can help impute some estimates for the addresses. Let's start by looking at the different towns from which the missing addresses stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "town\n",
       "Bridgeport          1\n",
       "Bristol             1\n",
       "Brookfield          1\n",
       "Hartford            1\n",
       "Litchfield          1\n",
       "Manchester          1\n",
       "New Milford         1\n",
       "Norfolk             1\n",
       "North Haven         1\n",
       "North Stonington    1\n",
       "Pomfret             1\n",
       "Shelton             1\n",
       "South Windsor       1\n",
       "Sterling            1\n",
       "Waterbury           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the count of different towns present for missing addresses\n",
    "raw_df[raw_df['address'].isna()].value_counts('town')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start with Bridgeport. We will check all the listings with the same price as the missing addresses from bridgeport. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129235</th>\n",
       "      <td>12242</td>\n",
       "      <td>2001</td>\n",
       "      <td>07/16/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>46.286154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130650</th>\n",
       "      <td>12040</td>\n",
       "      <td>2001</td>\n",
       "      <td>06/25/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>58500.0</td>\n",
       "      <td>36.000342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131987</th>\n",
       "      <td>10557</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/10/2001</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>58.500556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133784</th>\n",
       "      <td>10937</td>\n",
       "      <td>2001</td>\n",
       "      <td>02/06/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>39.736226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137339</th>\n",
       "      <td>10803</td>\n",
       "      <td>2001</td>\n",
       "      <td>01/17/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>41.294510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139479</th>\n",
       "      <td>11378</td>\n",
       "      <td>2001</td>\n",
       "      <td>04/05/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>SUCCESS VLG BLDG 20</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>50.143333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143481</th>\n",
       "      <td>11379</td>\n",
       "      <td>2001</td>\n",
       "      <td>04/05/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>SUCCESS VLG BLDG 5</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>140.401333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143525</th>\n",
       "      <td>12129</td>\n",
       "      <td>2001</td>\n",
       "      <td>07/02/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>32.400308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147082</th>\n",
       "      <td>10639</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/19/2001</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>SUCCESS VILLAGE 274-54</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>27.710789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148982</th>\n",
       "      <td>10544</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/07/2001</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>41500.0</td>\n",
       "      <td>50.747470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149634</th>\n",
       "      <td>10640</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/19/2001</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>46.800444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153040</th>\n",
       "      <td>12876</td>\n",
       "      <td>2001</td>\n",
       "      <td>09/25/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>50.143333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        serial_number  list_year date_recorded        town  \\\n",
       "129235          12242       2001    07/16/2002  Bridgeport   \n",
       "130650          12040       2001    06/25/2002  Bridgeport   \n",
       "131987          10557       2001    12/10/2001  Bridgeport   \n",
       "133784          10937       2001    02/06/2002  Bridgeport   \n",
       "137339          10803       2001    01/17/2002  Bridgeport   \n",
       "139479          11378       2001    04/05/2002  Bridgeport   \n",
       "143481          11379       2001    04/05/2002  Bridgeport   \n",
       "143525          12129       2001    07/02/2002  Bridgeport   \n",
       "147082          10639       2001    12/19/2001  Bridgeport   \n",
       "148982          10544       2001    12/07/2001  Bridgeport   \n",
       "149634          10640       2001    12/19/2001  Bridgeport   \n",
       "153040          12876       2001    09/25/2002  Bridgeport   \n",
       "\n",
       "                       address  assessed_value  sale_amount  sales_ratio  \\\n",
       "129235         300 SUCCESS AVE       2106020.0      45500.0    46.286154   \n",
       "130650         300 SUCCESS AVE       2106020.0      58500.0    36.000342   \n",
       "131987         300 SUCCESS AVE       2106020.0      36000.0    58.500556   \n",
       "133784         300 SUCCESS AVE       2106020.0      53000.0    39.736226   \n",
       "137339         300 SUCCESS AVE       2106020.0      51000.0    41.294510   \n",
       "139479     SUCCESS VLG BLDG 20       2106020.0      42000.0    50.143333   \n",
       "143481      SUCCESS VLG BLDG 5       2106020.0      15000.0   140.401333   \n",
       "143525         300 SUCCESS AVE       2106020.0      65000.0    32.400308   \n",
       "147082  SUCCESS VILLAGE 274-54       2106020.0      76000.0    27.710789   \n",
       "148982         300 SUCCESS AVE       2106020.0      41500.0    50.747470   \n",
       "149634                     NaN       2106020.0      45000.0    46.800444   \n",
       "153040         300 SUCCESS AVE       2106020.0      42000.0    50.143333   \n",
       "\n",
       "       property_type residential_type  \n",
       "129235           NaN              NaN  \n",
       "130650           NaN              NaN  \n",
       "131987           NaN              NaN  \n",
       "133784           NaN              NaN  \n",
       "137339           NaN              NaN  \n",
       "139479           NaN              NaN  \n",
       "143481           NaN              NaN  \n",
       "143525           NaN              NaN  \n",
       "147082           NaN              NaN  \n",
       "148982           NaN              NaN  \n",
       "149634           NaN              NaN  \n",
       "153040           NaN              NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice out all the rows where the town  and assesed_value is same as our first missing address\n",
    "raw_df[(raw_df['town'] == 'Bridgeport')&(raw_df['assessed_value']==2106020.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that '300 Success Avenue' was put on the market several times. It has the same `assessed_value` and it is safe to presume this may be the address for the first missing row. We can impute this address for the first missing row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "serial_number            10640\n",
       "list_year                 2001\n",
       "date_recorded       12/19/2001\n",
       "town                Bridgeport\n",
       "address                    NaN\n",
       "assessed_value       2106020.0\n",
       "sale_amount            45000.0\n",
       "sales_ratio          46.800444\n",
       "property_type              NaN\n",
       "residential_type           NaN\n",
       "Name: 149634, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the index of the first row with missing address\n",
    "raw_df.loc[149634, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's impute the address below with the one we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the address with the value we found\n",
    "raw_df.loc[149634, [\"address\"]] = '300 SUCCESS AVE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm this worked before moving on to other rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "serial_number                 10640\n",
       "list_year                      2001\n",
       "date_recorded            12/19/2001\n",
       "town                     Bridgeport\n",
       "address             300 SUCCESS AVE\n",
       "assessed_value            2106020.0\n",
       "sale_amount                 45000.0\n",
       "sales_ratio               46.800444\n",
       "property_type                   NaN\n",
       "residential_type                NaN\n",
       "Name: 149634, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check the index of the first row with missing address\n",
    "raw_df.loc[149634, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this worked, we can now manually  try to find other missing addresses and impute in the same manner. Alphabetically the next town is Bristol with assessed_value of 104100.0.  \n",
    "As this is a repeated procedure, we can create a function to undertake this search and extract the address that matches our values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which takes in a name of town and and the assessed value \n",
    "def address_search(town, assessed_val):\n",
    "    \"\"\"\n",
    "    The function takes the name of the town and the assessed value to find \n",
    "    other values in the dataset matching these two. \n",
    "\n",
    "    It counts the values of all the results and gives the address which has the\n",
    "    highest count. \n",
    "\n",
    "    If the exact assessed value is not found then the function searches wider\n",
    "    assessed_val by varying the range by a 1000$. \n",
    "\n",
    "    ----------------------------------------------------------------------------\n",
    "    INPUT:\n",
    "    town : string\n",
    "    assessed_val : float\n",
    "\n",
    "    OUTPUT:\n",
    "    Address of the highest count\n",
    "    \n",
    "    \"\"\"\n",
    "    # Assert that the town has to be a string\n",
    "    assert isinstance(town, str), \"Please use a string within the DataFrame's town column\"\n",
    "     # Assert that the assessed_val has to be a float\n",
    "    assert isinstance(assessed_val, float), \"Please use a float to denote the 'assessed_val'\"\n",
    "    \n",
    "    # Create a dataframe with the conditions given in the parameters\n",
    "    address_df =  raw_df[(raw_df['town'] == town)&(raw_df['assessed_value']==assessed_val)]\n",
    "\n",
    "    # If the number of rows in the DataFrame are more than 1\n",
    "    if len(address_df) >=1:\n",
    "        \n",
    "        # Print the value counts of the addresses with given parameters\n",
    "        print(address_df.value_counts('address'))\n",
    "\n",
    "        # Return the address with the most value counts\n",
    "        return address_df.value_counts('address').index[0]\n",
    "    \n",
    "    # If there are no results matching the paramters then\n",
    "    else:\n",
    "\n",
    "        # While there are no results showing under current parameters\n",
    "        while len(address_df) < 1:\n",
    "            print(\"No exact assessed_value found, trying wider values...\")\n",
    "            \n",
    "            # Add an increasing upper and lower bound of assessed_value (+/-500) \n",
    "            lower_assessed = assessed_val - 500\n",
    "            higher_assessed = assessed_val + 500\n",
    "\n",
    "            # Check with new bounds of assessed_value to see if there are any addresses\n",
    "            address_df =  raw_df[(raw_df['town'] == town)&(raw_df['assessed_value'] > lower_assessed)&(raw_df['assessed_value'] < higher_assessed)]\n",
    "            \n",
    "            print(address_df[[\"list_year\", \"address\", \"assessed_value\", \"sale_amount\"]])\n",
    "            # Return the most frequently obtained address\n",
    "            print(address_df.value_counts('address'))\n",
    "            return address_df.value_counts('address').index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above can be expanded further to automatically fill the missing addresses, however it is important to QC the information before imputation. Therefore, the author will QC the addresses and their value counts before imputing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the function can be used to find the approximate address for Bristol with an assessed_value of 104100.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address\n",
      "180 FARMINGTON AVE    1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'180 FARMINGTON AVE'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_search(\"Bristol\", 104100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be only 1 address with the exact value in Bristol. We can explore it further to see if it's a good fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240024</th>\n",
       "      <td>30734</td>\n",
       "      <td>2003</td>\n",
       "      <td>04/07/2004</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>180 FARMINGTON AVE</td>\n",
       "      <td>104100.0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>0.671613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        serial_number  list_year date_recorded     town             address  \\\n",
       "240024          30734       2003    04/07/2004  Bristol  180 FARMINGTON AVE   \n",
       "\n",
       "        assessed_value  sale_amount  sales_ratio property_type  \\\n",
       "240024        104100.0     155000.0     0.671613           NaN   \n",
       "\n",
       "       residential_type  \n",
       "240024              NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[raw_df['address'] == '180 FARMINGTON AVE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check above in the [missing addressess](#missing_addresses), then both the `assessed_val` and `sale_amount` from the missing address match this result. Therefore it will be imputed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address\n",
      "180 FARMINGTON AVE    1\n",
      "Name: count, dtype: int64\n",
      "serial_number                    50862\n",
      "list_year                         2005\n",
      "date_recorded               05/16/2006\n",
      "town                           Bristol\n",
      "address             180 FARMINGTON AVE\n",
      "assessed_value                104100.0\n",
      "sale_amount                   155000.0\n",
      "sales_ratio                   0.671613\n",
      "property_type                      NaN\n",
      "residential_type                   NaN\n",
      "Name: 396820, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Save the output of the function in a variable\n",
    "impute_value = address_search(\"Bristol\", 104100.0)\n",
    "\n",
    "# Impute the value to the missing address\n",
    "raw_df.loc[396820, [\"address\"]] = impute_value\n",
    "\n",
    "# Sanity Check to ensure the imputation worked\n",
    "print(raw_df.loc[396820])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[149634,\n",
       " 263002,\n",
       " 284781,\n",
       " 310474,\n",
       " 330004,\n",
       " 368444,\n",
       " 372035,\n",
       " 396820,\n",
       " 471551,\n",
       " 471586,\n",
       " 480102,\n",
       " 499563,\n",
       " 918890,\n",
       " 948235,\n",
       " 952051]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_address_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start appending addresses by index and pop the ones which have been completed from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
