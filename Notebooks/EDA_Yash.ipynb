{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">Housing Market Predictor</p> \n",
    "\n",
    "**Start Date:** 2024-03-18  \n",
    "**Authors:**  *Laura Cornejo Paulino * and *Shreyas Chitransh* \n",
    "\n",
    "## Introduciton\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "In this project we explore historical housing data and construct predictive modeling to predict housing prices with the hopes of capturing the decline in the current (2024) housing market. \n",
    "\n",
    "The data can be found in the following [location](https://drive.google.com/file/d/1sNm33rOHkcqPwb1QA_JnLT2VFlOlnPW7/view?usp=drive_link).\n",
    "\n",
    "\n",
    "Once the data is in the appropriate directory we can conduct a big picture exploration of our data. Let's start by loading a few of the important libraries and then look at our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "import numpy as np                      # Working with arrays \n",
    "import pandas as pd                     # Working with Datasets\n",
    "from matplotlib import pyplot as plt    # Creating plots and viewing images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the data with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"data/Real_Estate_Sales_2001-2021_GL.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the data using `.head()` to see the first few rows and guage any insights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>List Year</th>\n",
       "      <th>Date Recorded</th>\n",
       "      <th>Town</th>\n",
       "      <th>Address</th>\n",
       "      <th>Assessed Value</th>\n",
       "      <th>Sale Amount</th>\n",
       "      <th>Sales Ratio</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Residential Type</th>\n",
       "      <th>Non Use Code</th>\n",
       "      <th>Assessor Remarks</th>\n",
       "      <th>OPM remarks</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020348</td>\n",
       "      <td>2020</td>\n",
       "      <td>09/13/2021</td>\n",
       "      <td>Ansonia</td>\n",
       "      <td>230 WAKELEE AVE</td>\n",
       "      <td>150500.0</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>2020</td>\n",
       "      <td>10/02/2020</td>\n",
       "      <td>Ashford</td>\n",
       "      <td>390 TURNPIKE RD</td>\n",
       "      <td>253000.0</td>\n",
       "      <td>430000.0</td>\n",
       "      <td>0.5883</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210317</td>\n",
       "      <td>2021</td>\n",
       "      <td>07/05/2022</td>\n",
       "      <td>Avon</td>\n",
       "      <td>53 COTSWOLD WAY</td>\n",
       "      <td>329730.0</td>\n",
       "      <td>805000.0</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-72.846365959 41.781677018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200212</td>\n",
       "      <td>2020</td>\n",
       "      <td>03/09/2021</td>\n",
       "      <td>Avon</td>\n",
       "      <td>5 CHESTNUT DRIVE</td>\n",
       "      <td>130400.0</td>\n",
       "      <td>179900.0</td>\n",
       "      <td>0.7248</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Condo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200243</td>\n",
       "      <td>2020</td>\n",
       "      <td>04/13/2021</td>\n",
       "      <td>Avon</td>\n",
       "      <td>111 NORTHINGTON DRIVE</td>\n",
       "      <td>619290.0</td>\n",
       "      <td>890000.0</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial Number  List Year Date Recorded     Town                Address  \\\n",
       "0        2020348       2020    09/13/2021  Ansonia        230 WAKELEE AVE   \n",
       "1          20002       2020    10/02/2020  Ashford        390 TURNPIKE RD   \n",
       "2         210317       2021    07/05/2022     Avon        53 COTSWOLD WAY   \n",
       "3         200212       2020    03/09/2021     Avon       5 CHESTNUT DRIVE   \n",
       "4         200243       2020    04/13/2021     Avon  111 NORTHINGTON DRIVE   \n",
       "\n",
       "   Assessed Value  Sale Amount  Sales Ratio Property Type Residential Type  \\\n",
       "0        150500.0     325000.0       0.4630    Commercial              NaN   \n",
       "1        253000.0     430000.0       0.5883   Residential    Single Family   \n",
       "2        329730.0     805000.0       0.4096   Residential    Single Family   \n",
       "3        130400.0     179900.0       0.7248   Residential            Condo   \n",
       "4        619290.0     890000.0       0.6958   Residential    Single Family   \n",
       "\n",
       "  Non Use Code Assessor Remarks OPM remarks  \\\n",
       "0          NaN              NaN         NaN   \n",
       "1          NaN              NaN         NaN   \n",
       "2          NaN              NaN         NaN   \n",
       "3          NaN              NaN         NaN   \n",
       "4          NaN              NaN         NaN   \n",
       "\n",
       "                             Location  \n",
       "0                                 NaN  \n",
       "1                                 NaN  \n",
       "2  POINT (-72.846365959 41.781677018)  \n",
       "3                                 NaN  \n",
       "4                                 NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be specific columns related to:\n",
    "- `Serial Number` (Should be numerical)\n",
    "- `List Year` (May be redundant as we have a Date column)\n",
    "- `Date Recorded` that the listing was recorded (Need to check if it's datetime)\n",
    "- `Town` of the listing (Categorical)\n",
    "- `Address` of the listing (String)\n",
    "- `Assessed Value` of the listing (Float in USD)\n",
    "- `Sale Amount` (Need to check whether it is integer, but should be numerical overall)\n",
    "- `Sales Ratio` (Float of assesed value divided by Sale amount)\n",
    "- `Property Type` (Categorical String)\n",
    "- `Residential Type` (Categorical)\n",
    "- `Non Use Code`  Unsure what the column contains but it has a lot of NaNs\n",
    "- `Assesor Remark` Contains a lot of NaNs and likely string of comments by Assesor\n",
    "- `OPM Remark` Contains a lot of NaN's and likely string of comments by OPM (Find out what OPM is)\n",
    "- `Location` contains some latitude and longitude data but also a lot of NaNs\n",
    "\n",
    "Below we can confirm whether the expected data types match or whether they need to be reset using `.info()` which can give data types, index listings and missing indices in columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1054159 entries, 0 to 1054158\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   Serial Number     1054159 non-null  int64  \n",
      " 1   List Year         1054159 non-null  int64  \n",
      " 2   Date Recorded     1054157 non-null  object \n",
      " 3   Town              1054159 non-null  object \n",
      " 4   Address           1054108 non-null  object \n",
      " 5   Assessed Value    1054159 non-null  float64\n",
      " 6   Sale Amount       1054159 non-null  float64\n",
      " 7   Sales Ratio       1054159 non-null  float64\n",
      " 8   Property Type     671713 non-null   object \n",
      " 9   Residential Type  660275 non-null   object \n",
      " 10  Non Use Code      302242 non-null   object \n",
      " 11  Assessor Remarks  161472 non-null   object \n",
      " 12  OPM remarks       11564 non-null    object \n",
      " 13  Location          254643 non-null   object \n",
      "dtypes: float64(3), int64(2), object(9)\n",
      "memory usage: 112.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Use .info()\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------\n",
    "We can explore the missing information that needs to be imputed and/or dropped based on the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The index seems to be correct and there are 1.054 Million rows of data with 14 columns.\n",
    "- The first 8 columns all seem to have almost all of the data recorded. However we need to ensure that there are no codes or categories in there which relate to `unknown` which is still considered missing information. \n",
    "- The `Date Recorded` needs to be converted to datetime datatype. \n",
    "- A lot of data is missing in:\n",
    "    - `Property Type`;\n",
    "    - `Residential Type`; \n",
    "    - `Non Use Code`;\n",
    "    - `Assesor Remark`; \n",
    "    - `OPM Remark`;\n",
    "    - `Location`.\n",
    "\n",
    "We can check the total number of rows missing for the columns and the exact percentage below that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial Number             0\n",
       "List Year                 0\n",
       "Date Recorded             2\n",
       "Town                      0\n",
       "Address                  51\n",
       "Assessed Value            0\n",
       "Sale Amount               0\n",
       "Sales Ratio               0\n",
       "Property Type        382446\n",
       "Residential Type     393884\n",
       "Non Use Code         751917\n",
       "Assessor Remarks     892687\n",
       "OPM remarks         1042595\n",
       "Location             799516\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at all of the rows with null vales and sum them columnwise\n",
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial Number        0.000000\n",
       "List Year            0.000000\n",
       "Date Recorded        0.000190\n",
       "Town                 0.000000\n",
       "Address              0.004838\n",
       "Assessed Value       0.000000\n",
       "Sale Amount          0.000000\n",
       "Sales Ratio          0.000000\n",
       "Property Type       36.279726\n",
       "Residential Type    37.364762\n",
       "Non Use Code        71.328614\n",
       "Assessor Remarks    84.682387\n",
       "OPM remarks         98.903012\n",
       "Location            75.843967\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide the sum of total null values by the total number of rows to get percentage of null values\n",
    "raw_df.isna().sum()/raw_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 rows of `Date Recorded` missing which is good, as this is a time series problem and we will eventually be turning the Dates into an index after resampling them.   \n",
    "\n",
    "There are 51 addresses missing which we will attempt to impute using other columns if we can.   \n",
    "\n",
    "`Property Type` and `Residential Type` are bothing missing 36-37% of data and we can check whether the same rows are missing both the pieces of data.  \n",
    "\n",
    "`Non Use Code`, `Assessor Remarks`, `OPM Remarks` and `Location` are all missing over 70% of the data. \n",
    "\n",
    "We will likely not be using these columns anyway (unless we want a non time-series based analysis). Therefore, for now we can drop these columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the discussed columns, inplace so the dataframe doesn't need to be overwritten  \n",
    "# and axis=1 is referring to columns\n",
    "raw_df.drop(['Non Use Code', 'Assessor Remarks', 'OPM remarks', 'Location'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conduct a sanity check below to ensure that the columns indeed got dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1054159 entries, 0 to 1054158\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   Serial Number     1054159 non-null  int64  \n",
      " 1   List Year         1054159 non-null  int64  \n",
      " 2   Date Recorded     1054157 non-null  object \n",
      " 3   Town              1054159 non-null  object \n",
      " 4   Address           1054108 non-null  object \n",
      " 5   Assessed Value    1054159 non-null  float64\n",
      " 6   Sale Amount       1054159 non-null  float64\n",
      " 7   Sales Ratio       1054159 non-null  float64\n",
      " 8   Property Type     671713 non-null   object \n",
      " 9   Residential Type  660275 non-null   object \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 80.4+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are sure that the columns got dropped, we can go ahead and optimise the dataset more to our workflow. As a first step we will standardise the column names to include underscore instead of space to make it easier for coding. We will also be converting all the column names to lower case for the same reason. Note that this is a personal choice and not standardised practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a for loop to iterate over all of the columns by calling all the columns from the raw_df\n",
    "for column in raw_df.columns:\n",
    "\n",
    "    # Store a version of the original column name for later use\n",
    "    original_column = column\n",
    "\n",
    "    # For the column name, lower te case and replace space with underscore\n",
    "    column = column.lower().replace(\" \", \"_\")\n",
    "\n",
    "    # Replace the dataframe by renaming the columns by taking original column name saved\n",
    "    # and replacing it with the updated column\n",
    "    raw_df = raw_df.rename(columns={original_column:column})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm the renaming worked for the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1054159 entries, 0 to 1054158\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   serial_number     1054159 non-null  int64  \n",
      " 1   list_year         1054159 non-null  int64  \n",
      " 2   date_recorded     1054157 non-null  object \n",
      " 3   town              1054159 non-null  object \n",
      " 4   address           1054108 non-null  object \n",
      " 5   assessed_value    1054159 non-null  float64\n",
      " 6   sale_amount       1054159 non-null  float64\n",
      " 7   sales_ratio       1054159 non-null  float64\n",
      " 8   property_type     671713 non-null   object \n",
      " 9   residential_type  660275 non-null   object \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 80.4+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the column names are replaced, we can start by checking some of the distributions that can assist us with better understanding the data and may even helo us with imputing missing data. Accordingly we will start with visualising the rows where `address` is missing. We will start by looking at the first 10 rows of data where `address` is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75944</th>\n",
       "      <td>39999</td>\n",
       "      <td>2003</td>\n",
       "      <td>02/02/2004</td>\n",
       "      <td>West Haven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89004</th>\n",
       "      <td>49996</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/17/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101602</th>\n",
       "      <td>48886</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/13/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145969</th>\n",
       "      <td>10537</td>\n",
       "      <td>2001</td>\n",
       "      <td>02/05/2002</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149638</th>\n",
       "      <td>10640</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/19/2001</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>46.800444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234863</th>\n",
       "      <td>20280</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236356</th>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263008</th>\n",
       "      <td>30125</td>\n",
       "      <td>2003</td>\n",
       "      <td>11/10/2003</td>\n",
       "      <td>New Milford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55090.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.137725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276118</th>\n",
       "      <td>39998</td>\n",
       "      <td>2003</td>\n",
       "      <td>08/12/2004</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284788</th>\n",
       "      <td>30100</td>\n",
       "      <td>2003</td>\n",
       "      <td>05/20/2004</td>\n",
       "      <td>North Stonington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7210.0</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>0.048389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289386</th>\n",
       "      <td>39995</td>\n",
       "      <td>2003</td>\n",
       "      <td>02/02/2004</td>\n",
       "      <td>West Haven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296156</th>\n",
       "      <td>39998</td>\n",
       "      <td>2003</td>\n",
       "      <td>02/20/2004</td>\n",
       "      <td>West Haven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296748</th>\n",
       "      <td>40088</td>\n",
       "      <td>2004</td>\n",
       "      <td>11/01/2004</td>\n",
       "      <td>Groton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7060035.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297284</th>\n",
       "      <td>48889</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/02/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310485</th>\n",
       "      <td>40080</td>\n",
       "      <td>2004</td>\n",
       "      <td>11/24/2004</td>\n",
       "      <td>Brookfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147340.0</td>\n",
       "      <td>1015000.0</td>\n",
       "      <td>0.145163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313376</th>\n",
       "      <td>39997</td>\n",
       "      <td>2003</td>\n",
       "      <td>02/02/2004</td>\n",
       "      <td>West Haven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315350</th>\n",
       "      <td>48888</td>\n",
       "      <td>2004</td>\n",
       "      <td>03/03/2005</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319336</th>\n",
       "      <td>49999</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/12/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329404</th>\n",
       "      <td>48887</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/30/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330019</th>\n",
       "      <td>40070</td>\n",
       "      <td>2004</td>\n",
       "      <td>10/12/2004</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54950.0</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331974</th>\n",
       "      <td>40059</td>\n",
       "      <td>2004</td>\n",
       "      <td>04/29/2005</td>\n",
       "      <td>Harwinton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334893</th>\n",
       "      <td>48884</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/13/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338946</th>\n",
       "      <td>48885</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/13/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340556</th>\n",
       "      <td>49997</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/27/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341747</th>\n",
       "      <td>49994</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/12/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342559</th>\n",
       "      <td>48811</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/22/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344259</th>\n",
       "      <td>48810</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/02/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344747</th>\n",
       "      <td>49993</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/23/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344819</th>\n",
       "      <td>40318</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/07/2005</td>\n",
       "      <td>East Hampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345481</th>\n",
       "      <td>48888</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/08/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345865</th>\n",
       "      <td>49998</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/12/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346288</th>\n",
       "      <td>41588</td>\n",
       "      <td>2004</td>\n",
       "      <td>09/20/2005</td>\n",
       "      <td>Meriden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348686</th>\n",
       "      <td>49995</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/12/2005</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365828</th>\n",
       "      <td>49999</td>\n",
       "      <td>2004</td>\n",
       "      <td>07/05/2005</td>\n",
       "      <td>Salem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367924</th>\n",
       "      <td>49998</td>\n",
       "      <td>2004</td>\n",
       "      <td>07/05/2005</td>\n",
       "      <td>Salem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368474</th>\n",
       "      <td>41230</td>\n",
       "      <td>2004</td>\n",
       "      <td>03/10/2005</td>\n",
       "      <td>Waterbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234500.0</td>\n",
       "      <td>425000.0</td>\n",
       "      <td>0.551765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370597</th>\n",
       "      <td>48992</td>\n",
       "      <td>2004</td>\n",
       "      <td>05/12/2005</td>\n",
       "      <td>Salem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372066</th>\n",
       "      <td>40198</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/02/2005</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50200.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>0.143429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374438</th>\n",
       "      <td>49997</td>\n",
       "      <td>2004</td>\n",
       "      <td>07/08/2005</td>\n",
       "      <td>Salem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391119</th>\n",
       "      <td>40285</td>\n",
       "      <td>2004</td>\n",
       "      <td>01/11/2005</td>\n",
       "      <td>Torrington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155800.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396853</th>\n",
       "      <td>50862</td>\n",
       "      <td>2005</td>\n",
       "      <td>05/16/2006</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104100.0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>0.671613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462293</th>\n",
       "      <td>60058</td>\n",
       "      <td>2006</td>\n",
       "      <td>09/17/2007</td>\n",
       "      <td>Lyme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3656.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466717</th>\n",
       "      <td>60474</td>\n",
       "      <td>2006</td>\n",
       "      <td>07/30/2007</td>\n",
       "      <td>Farmington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>453369.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>Single Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471408</th>\n",
       "      <td>60054</td>\n",
       "      <td>2006</td>\n",
       "      <td>12/08/2006</td>\n",
       "      <td>New Fairfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471587</th>\n",
       "      <td>60032</td>\n",
       "      <td>2006</td>\n",
       "      <td>02/21/2007</td>\n",
       "      <td>Sterling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181310.0</td>\n",
       "      <td>301500.0</td>\n",
       "      <td>0.601360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471622</th>\n",
       "      <td>60159</td>\n",
       "      <td>2006</td>\n",
       "      <td>08/21/2007</td>\n",
       "      <td>Litchfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55190.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0.919833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480138</th>\n",
       "      <td>60043</td>\n",
       "      <td>2006</td>\n",
       "      <td>07/19/2007</td>\n",
       "      <td>Pomfret</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445340.0</td>\n",
       "      <td>875000.0</td>\n",
       "      <td>0.508960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499599</th>\n",
       "      <td>60237</td>\n",
       "      <td>2006</td>\n",
       "      <td>04/02/2007</td>\n",
       "      <td>South Windsor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72340.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.321511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918926</th>\n",
       "      <td>170165</td>\n",
       "      <td>2017</td>\n",
       "      <td>12/08/2017</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129300.0</td>\n",
       "      <td>224000.0</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>Two Family</td>\n",
       "      <td>Two Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948271</th>\n",
       "      <td>172767</td>\n",
       "      <td>2017</td>\n",
       "      <td>01/12/2018</td>\n",
       "      <td>Shelton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227500.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>Condo</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        serial_number  list_year date_recorded              town address  \\\n",
       "75944           39999       2003    02/02/2004        West Haven     NaN   \n",
       "89004           49996       2004    05/17/2005            Lisbon     NaN   \n",
       "101602          48886       2004    06/13/2005            Lisbon     NaN   \n",
       "145969          10537       2001    02/05/2002          Hartford     NaN   \n",
       "149638          10640       2001    12/19/2001        Bridgeport     NaN   \n",
       "234863          20280       2002           NaN            Orange     NaN   \n",
       "236356              0       2002           NaN            Orange     NaN   \n",
       "263008          30125       2003    11/10/2003       New Milford     NaN   \n",
       "276118          39998       2003    08/12/2004            Lisbon     NaN   \n",
       "284788          30100       2003    05/20/2004  North Stonington     NaN   \n",
       "289386          39995       2003    02/02/2004        West Haven     NaN   \n",
       "296156          39998       2003    02/20/2004        West Haven     NaN   \n",
       "296748          40088       2004    11/01/2004            Groton     NaN   \n",
       "297284          48889       2004    06/02/2005            Lisbon     NaN   \n",
       "310485          40080       2004    11/24/2004        Brookfield     NaN   \n",
       "313376          39997       2003    02/02/2004        West Haven     NaN   \n",
       "315350          48888       2004    03/03/2005        Bridgeport     NaN   \n",
       "319336          49999       2004    05/12/2005            Lisbon     NaN   \n",
       "329404          48887       2004    06/30/2005            Lisbon     NaN   \n",
       "330019          40070       2004    10/12/2004          Hartford     NaN   \n",
       "331974          40059       2004    04/29/2005         Harwinton     NaN   \n",
       "334893          48884       2004    05/13/2005            Lisbon     NaN   \n",
       "338946          48885       2004    05/13/2005            Lisbon     NaN   \n",
       "340556          49997       2004    05/27/2005            Lisbon     NaN   \n",
       "341747          49994       2004    05/12/2005            Lisbon     NaN   \n",
       "342559          48811       2004    06/22/2005            Lisbon     NaN   \n",
       "344259          48810       2004    06/02/2005            Lisbon     NaN   \n",
       "344747          49993       2004    05/23/2005            Lisbon     NaN   \n",
       "344819          40318       2004    06/07/2005      East Hampton     NaN   \n",
       "345481          48888       2004    06/08/2005            Lisbon     NaN   \n",
       "345865          49998       2004    05/12/2005            Lisbon     NaN   \n",
       "346288          41588       2004    09/20/2005           Meriden     NaN   \n",
       "348686          49995       2004    05/12/2005            Lisbon     NaN   \n",
       "365828          49999       2004    07/05/2005             Salem     NaN   \n",
       "367924          49998       2004    07/05/2005             Salem     NaN   \n",
       "368474          41230       2004    03/10/2005         Waterbury     NaN   \n",
       "370597          48992       2004    05/12/2005             Salem     NaN   \n",
       "372066          40198       2004    06/02/2005           Norfolk     NaN   \n",
       "374438          49997       2004    07/08/2005             Salem     NaN   \n",
       "391119          40285       2004    01/11/2005        Torrington     NaN   \n",
       "396853          50862       2005    05/16/2006           Bristol     NaN   \n",
       "462293          60058       2006    09/17/2007              Lyme     NaN   \n",
       "466717          60474       2006    07/30/2007        Farmington     NaN   \n",
       "471408          60054       2006    12/08/2006     New Fairfield     NaN   \n",
       "471587          60032       2006    02/21/2007          Sterling     NaN   \n",
       "471622          60159       2006    08/21/2007        Litchfield     NaN   \n",
       "480138          60043       2006    07/19/2007           Pomfret     NaN   \n",
       "499599          60237       2006    04/02/2007     South Windsor     NaN   \n",
       "918926         170165       2017    12/08/2017        Manchester     NaN   \n",
       "948271         172767       2017    01/12/2018           Shelton     NaN   \n",
       "\n",
       "        assessed_value  sale_amount  sales_ratio  property_type  \\\n",
       "75944              0.0          0.0     0.000000            NaN   \n",
       "89004              0.0          0.0     0.000000            NaN   \n",
       "101602             0.0          0.0     0.000000            NaN   \n",
       "145969             0.0     120000.0     0.000000            NaN   \n",
       "149638       2106020.0      45000.0    46.800444            NaN   \n",
       "234863             0.0          0.0     0.000000            NaN   \n",
       "236356             0.0          0.0     0.000000            NaN   \n",
       "263008         55090.0     400000.0     0.137725            NaN   \n",
       "276118             0.0          0.0     0.000000            NaN   \n",
       "284788          7210.0     149000.0     0.048389            NaN   \n",
       "289386             0.0          0.0     0.000000            NaN   \n",
       "296156             0.0          0.0     0.000000            NaN   \n",
       "296748             0.0    7060035.0     0.000000            NaN   \n",
       "297284             0.0          0.0     0.000000            NaN   \n",
       "310485        147340.0    1015000.0     0.145163            NaN   \n",
       "313376             0.0          0.0     0.000000            NaN   \n",
       "315350             0.0          0.0     0.000000            NaN   \n",
       "319336             0.0          0.0     0.000000            NaN   \n",
       "329404             0.0          0.0     0.000000            NaN   \n",
       "330019         54950.0     105000.0     0.523333            NaN   \n",
       "331974             0.0     450000.0     0.000000            NaN   \n",
       "334893             0.0          0.0     0.000000            NaN   \n",
       "338946             0.0          0.0     0.000000            NaN   \n",
       "340556             0.0          0.0     0.000000            NaN   \n",
       "341747             0.0          0.0     0.000000            NaN   \n",
       "342559             0.0          0.0     0.000000            NaN   \n",
       "344259             0.0          0.0     0.000000            NaN   \n",
       "344747             0.0          0.0     0.000000            NaN   \n",
       "344819             0.0     400000.0     0.000000            NaN   \n",
       "345481             0.0          0.0     0.000000            NaN   \n",
       "345865             0.0          0.0     0.000000            NaN   \n",
       "346288             0.0        100.0     0.000000            NaN   \n",
       "348686             0.0          0.0     0.000000            NaN   \n",
       "365828             0.0          0.0     0.000000            NaN   \n",
       "367924             0.0          0.0     0.000000            NaN   \n",
       "368474        234500.0     425000.0     0.551765            NaN   \n",
       "370597             0.0          0.0     0.000000            NaN   \n",
       "372066         50200.0     350000.0     0.143429            NaN   \n",
       "374438             0.0          0.0     0.000000            NaN   \n",
       "391119             0.0     155800.0     0.000000            NaN   \n",
       "396853        104100.0     155000.0     0.671613            NaN   \n",
       "462293             0.0       3656.0     0.000000            NaN   \n",
       "466717             0.0     453369.0     0.000000  Single Family   \n",
       "471408             0.0       3500.0     0.000000            NaN   \n",
       "471587        181310.0     301500.0     0.601360            NaN   \n",
       "471622         55190.0      60000.0     0.919833            NaN   \n",
       "480138        445340.0     875000.0     0.508960            NaN   \n",
       "499599         72340.0     225000.0     0.321511            NaN   \n",
       "918926        129300.0     224000.0     0.577200     Two Family   \n",
       "948271        227500.0     500000.0     0.455000          Condo   \n",
       "\n",
       "       residential_type  \n",
       "75944               NaN  \n",
       "89004               NaN  \n",
       "101602              NaN  \n",
       "145969              NaN  \n",
       "149638              NaN  \n",
       "234863              NaN  \n",
       "236356              NaN  \n",
       "263008              NaN  \n",
       "276118              NaN  \n",
       "284788              NaN  \n",
       "289386              NaN  \n",
       "296156              NaN  \n",
       "296748              NaN  \n",
       "297284              NaN  \n",
       "310485              NaN  \n",
       "313376              NaN  \n",
       "315350              NaN  \n",
       "319336              NaN  \n",
       "329404              NaN  \n",
       "330019              NaN  \n",
       "331974              NaN  \n",
       "334893              NaN  \n",
       "338946              NaN  \n",
       "340556              NaN  \n",
       "341747              NaN  \n",
       "342559              NaN  \n",
       "344259              NaN  \n",
       "344747              NaN  \n",
       "344819              NaN  \n",
       "345481              NaN  \n",
       "345865              NaN  \n",
       "346288              NaN  \n",
       "348686              NaN  \n",
       "365828              NaN  \n",
       "367924              NaN  \n",
       "368474              NaN  \n",
       "370597              NaN  \n",
       "372066              NaN  \n",
       "374438              NaN  \n",
       "391119              NaN  \n",
       "396853              NaN  \n",
       "462293              NaN  \n",
       "466717    Single Family  \n",
       "471408              NaN  \n",
       "471587              NaN  \n",
       "471622              NaN  \n",
       "480138              NaN  \n",
       "499599              NaN  \n",
       "918926       Two Family  \n",
       "948271            Condo  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[raw_df['address'].isna()].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has provided a lot of interesting insights immedietely. \n",
    "1. The 2 rows of missing `date_recorded` are also coinciding with missing address. \n",
    "2. There are a lot of listings where the `assessed_value` and/or `sale_amount` (and therefore `sales_ratio`) are 0. This is important to note as these values would be used in our data for the time series modeling.\n",
    "3. The dates of these listings with missing addresses are mostly quite old, around 2004-2007 which works better for our modeling as we will then have cleaner data for dates nearer to our target years of early 2020's.\n",
    "\n",
    "We can actually drop the address column too as it won't be used for the time series analysis, but as part of this workflow, we can also create a cleaner overall dataset that can potentially be used for other modelling aspects. For now, as there is no way to impute the addresses and the NaN addresses coincide with other missing information, we will drop the rows where both the `address` and `assessed_value` and/or `sale_amount` are missing. \n",
    "\n",
    "This will be achieved by checking all of the rows where `address` is missing and `sales_ratio` is 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows where address is null and sales_ratio is 0\n",
    "len(raw_df[(raw_df['address'].isna()) & (raw_df['sales_ratio']==0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total there are 36 rows of data with null `address` and `sales_ratio` of 0. We can drop these rows. We will also reset the index to make sure they fall in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the row indexes where the address is null and sales_ratio is 0. Reset the index after. \n",
    "raw_df = raw_df.drop(raw_df[(raw_df['address'].isna()) & (raw_df['sales_ratio']==0)].index, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm this has worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1054123 entries, 0 to 1054122\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   serial_number     1054123 non-null  int64  \n",
      " 1   list_year         1054123 non-null  int64  \n",
      " 2   date_recorded     1054123 non-null  object \n",
      " 3   town              1054123 non-null  object \n",
      " 4   address           1054108 non-null  object \n",
      " 5   assessed_value    1054123 non-null  float64\n",
      " 6   sale_amount       1054123 non-null  float64\n",
      " 7   sales_ratio       1054123 non-null  float64\n",
      " 8   property_type     671712 non-null   object \n",
      " 9   residential_type  660274 non-null   object \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 80.4+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the total missing data rows again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "serial_number            0\n",
       "list_year                0\n",
       "date_recorded            0\n",
       "town                     0\n",
       "address                 15\n",
       "assessed_value           0\n",
       "sale_amount              0\n",
       "sales_ratio              0\n",
       "property_type       382411\n",
       "residential_type    393849\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at all of the rows with null vales and sum them columnwise\n",
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are another 15 rows of addresses missing. Let's explore them. <a id='missing_addresses'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149634</th>\n",
       "      <td>10640</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/19/2001</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>46.800444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263002</th>\n",
       "      <td>30125</td>\n",
       "      <td>2003</td>\n",
       "      <td>11/10/2003</td>\n",
       "      <td>New Milford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55090.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.137725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284781</th>\n",
       "      <td>30100</td>\n",
       "      <td>2003</td>\n",
       "      <td>05/20/2004</td>\n",
       "      <td>North Stonington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7210.0</td>\n",
       "      <td>149000.0</td>\n",
       "      <td>0.048389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310474</th>\n",
       "      <td>40080</td>\n",
       "      <td>2004</td>\n",
       "      <td>11/24/2004</td>\n",
       "      <td>Brookfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147340.0</td>\n",
       "      <td>1015000.0</td>\n",
       "      <td>0.145163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330004</th>\n",
       "      <td>40070</td>\n",
       "      <td>2004</td>\n",
       "      <td>10/12/2004</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54950.0</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368444</th>\n",
       "      <td>41230</td>\n",
       "      <td>2004</td>\n",
       "      <td>03/10/2005</td>\n",
       "      <td>Waterbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234500.0</td>\n",
       "      <td>425000.0</td>\n",
       "      <td>0.551765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372035</th>\n",
       "      <td>40198</td>\n",
       "      <td>2004</td>\n",
       "      <td>06/02/2005</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50200.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>0.143429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396820</th>\n",
       "      <td>50862</td>\n",
       "      <td>2005</td>\n",
       "      <td>05/16/2006</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104100.0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>0.671613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471551</th>\n",
       "      <td>60032</td>\n",
       "      <td>2006</td>\n",
       "      <td>02/21/2007</td>\n",
       "      <td>Sterling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181310.0</td>\n",
       "      <td>301500.0</td>\n",
       "      <td>0.601360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471586</th>\n",
       "      <td>60159</td>\n",
       "      <td>2006</td>\n",
       "      <td>08/21/2007</td>\n",
       "      <td>Litchfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55190.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0.919833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480102</th>\n",
       "      <td>60043</td>\n",
       "      <td>2006</td>\n",
       "      <td>07/19/2007</td>\n",
       "      <td>Pomfret</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445340.0</td>\n",
       "      <td>875000.0</td>\n",
       "      <td>0.508960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499563</th>\n",
       "      <td>60237</td>\n",
       "      <td>2006</td>\n",
       "      <td>04/02/2007</td>\n",
       "      <td>South Windsor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72340.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.321511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918890</th>\n",
       "      <td>170165</td>\n",
       "      <td>2017</td>\n",
       "      <td>12/08/2017</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129300.0</td>\n",
       "      <td>224000.0</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>Two Family</td>\n",
       "      <td>Two Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948235</th>\n",
       "      <td>172767</td>\n",
       "      <td>2017</td>\n",
       "      <td>01/12/2018</td>\n",
       "      <td>Shelton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227500.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>Condo</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952051</th>\n",
       "      <td>17001</td>\n",
       "      <td>2017</td>\n",
       "      <td>10/02/2017</td>\n",
       "      <td>North Haven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193130.0</td>\n",
       "      <td>242000.0</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>Single Family</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        serial_number  list_year date_recorded              town address  \\\n",
       "149634          10640       2001    12/19/2001        Bridgeport     NaN   \n",
       "263002          30125       2003    11/10/2003       New Milford     NaN   \n",
       "284781          30100       2003    05/20/2004  North Stonington     NaN   \n",
       "310474          40080       2004    11/24/2004        Brookfield     NaN   \n",
       "330004          40070       2004    10/12/2004          Hartford     NaN   \n",
       "368444          41230       2004    03/10/2005         Waterbury     NaN   \n",
       "372035          40198       2004    06/02/2005           Norfolk     NaN   \n",
       "396820          50862       2005    05/16/2006           Bristol     NaN   \n",
       "471551          60032       2006    02/21/2007          Sterling     NaN   \n",
       "471586          60159       2006    08/21/2007        Litchfield     NaN   \n",
       "480102          60043       2006    07/19/2007           Pomfret     NaN   \n",
       "499563          60237       2006    04/02/2007     South Windsor     NaN   \n",
       "918890         170165       2017    12/08/2017        Manchester     NaN   \n",
       "948235         172767       2017    01/12/2018           Shelton     NaN   \n",
       "952051          17001       2017    10/02/2017       North Haven     NaN   \n",
       "\n",
       "        assessed_value  sale_amount  sales_ratio  property_type  \\\n",
       "149634       2106020.0      45000.0    46.800444            NaN   \n",
       "263002         55090.0     400000.0     0.137725            NaN   \n",
       "284781          7210.0     149000.0     0.048389            NaN   \n",
       "310474        147340.0    1015000.0     0.145163            NaN   \n",
       "330004         54950.0     105000.0     0.523333            NaN   \n",
       "368444        234500.0     425000.0     0.551765            NaN   \n",
       "372035         50200.0     350000.0     0.143429            NaN   \n",
       "396820        104100.0     155000.0     0.671613            NaN   \n",
       "471551        181310.0     301500.0     0.601360            NaN   \n",
       "471586         55190.0      60000.0     0.919833            NaN   \n",
       "480102        445340.0     875000.0     0.508960            NaN   \n",
       "499563         72340.0     225000.0     0.321511            NaN   \n",
       "918890        129300.0     224000.0     0.577200     Two Family   \n",
       "948235        227500.0     500000.0     0.455000          Condo   \n",
       "952051        193130.0     242000.0     0.798000  Single Family   \n",
       "\n",
       "       residential_type  \n",
       "149634              NaN  \n",
       "263002              NaN  \n",
       "284781              NaN  \n",
       "310474              NaN  \n",
       "330004              NaN  \n",
       "368444              NaN  \n",
       "372035              NaN  \n",
       "396820              NaN  \n",
       "471551              NaN  \n",
       "471586              NaN  \n",
       "480102              NaN  \n",
       "499563              NaN  \n",
       "918890       Two Family  \n",
       "948235            Condo  \n",
       "952051    Single Family  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[raw_df['address'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can append the indexes of the missing addresses in a list to use it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149634, 263002, 284781, 310474, 330004, 368444, 372035, 396820, 471551, 471586, 480102, 499563, 918890, 948235, 952051]\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store the addresses\n",
    "missing_address_list = []\n",
    "\n",
    "# For each index in the missing address lisst\n",
    "for add in raw_df[raw_df['address'].isna()].index:\n",
    "\n",
    "    # Add the index to the list\n",
    "    missing_address_list.append(add)\n",
    "\n",
    "# Sanity Check to see this worked\n",
    "print(missing_address_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these remaining missing `addresses`, we can see what type of addresses are present based on the town. It's likely that narrowing down the town with approximate prices can help impute some estimates for the addresses. Let's start by looking at the different towns from which the missing addresses stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "town\n",
       "Bridgeport          1\n",
       "Bristol             1\n",
       "Brookfield          1\n",
       "Hartford            1\n",
       "Litchfield          1\n",
       "Manchester          1\n",
       "New Milford         1\n",
       "Norfolk             1\n",
       "North Haven         1\n",
       "North Stonington    1\n",
       "Pomfret             1\n",
       "Shelton             1\n",
       "South Windsor       1\n",
       "Sterling            1\n",
       "Waterbury           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the count of different towns present for missing addresses\n",
    "raw_df[raw_df['address'].isna()].value_counts('town')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the missing addresses are from different towns and don't show a pattern in that front. Therefore, we can start with the first index in the list instead. We will check all the listings with the same price as the missing addresses from this index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "serial_number            10640\n",
       "list_year                 2001\n",
       "date_recorded       12/19/2001\n",
       "town                Bridgeport\n",
       "address                    NaN\n",
       "assessed_value       2106020.0\n",
       "sale_amount            45000.0\n",
       "sales_ratio          46.800444\n",
       "property_type              NaN\n",
       "residential_type           NaN\n",
       "Name: 149634, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.loc[149634,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `town` and `assessed_value` from here can be used to filter our data. We want the same `town` and same `assessed_value` as the original values for the data with missing `address`. Let's slice all the instances where the two variables match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129235</th>\n",
       "      <td>12242</td>\n",
       "      <td>2001</td>\n",
       "      <td>07/16/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>46.286154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130650</th>\n",
       "      <td>12040</td>\n",
       "      <td>2001</td>\n",
       "      <td>06/25/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>58500.0</td>\n",
       "      <td>36.000342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131987</th>\n",
       "      <td>10557</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/10/2001</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>58.500556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133784</th>\n",
       "      <td>10937</td>\n",
       "      <td>2001</td>\n",
       "      <td>02/06/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>39.736226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137339</th>\n",
       "      <td>10803</td>\n",
       "      <td>2001</td>\n",
       "      <td>01/17/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>41.294510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139479</th>\n",
       "      <td>11378</td>\n",
       "      <td>2001</td>\n",
       "      <td>04/05/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>SUCCESS VLG BLDG 20</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>50.143333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143481</th>\n",
       "      <td>11379</td>\n",
       "      <td>2001</td>\n",
       "      <td>04/05/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>SUCCESS VLG BLDG 5</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>140.401333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143525</th>\n",
       "      <td>12129</td>\n",
       "      <td>2001</td>\n",
       "      <td>07/02/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>32.400308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147082</th>\n",
       "      <td>10639</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/19/2001</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>SUCCESS VILLAGE 274-54</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>27.710789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148982</th>\n",
       "      <td>10544</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/07/2001</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>41500.0</td>\n",
       "      <td>50.747470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149634</th>\n",
       "      <td>10640</td>\n",
       "      <td>2001</td>\n",
       "      <td>12/19/2001</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>46.800444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153040</th>\n",
       "      <td>12876</td>\n",
       "      <td>2001</td>\n",
       "      <td>09/25/2002</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>300 SUCCESS AVE</td>\n",
       "      <td>2106020.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>50.143333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        serial_number  list_year date_recorded        town  \\\n",
       "129235          12242       2001    07/16/2002  Bridgeport   \n",
       "130650          12040       2001    06/25/2002  Bridgeport   \n",
       "131987          10557       2001    12/10/2001  Bridgeport   \n",
       "133784          10937       2001    02/06/2002  Bridgeport   \n",
       "137339          10803       2001    01/17/2002  Bridgeport   \n",
       "139479          11378       2001    04/05/2002  Bridgeport   \n",
       "143481          11379       2001    04/05/2002  Bridgeport   \n",
       "143525          12129       2001    07/02/2002  Bridgeport   \n",
       "147082          10639       2001    12/19/2001  Bridgeport   \n",
       "148982          10544       2001    12/07/2001  Bridgeport   \n",
       "149634          10640       2001    12/19/2001  Bridgeport   \n",
       "153040          12876       2001    09/25/2002  Bridgeport   \n",
       "\n",
       "                       address  assessed_value  sale_amount  sales_ratio  \\\n",
       "129235         300 SUCCESS AVE       2106020.0      45500.0    46.286154   \n",
       "130650         300 SUCCESS AVE       2106020.0      58500.0    36.000342   \n",
       "131987         300 SUCCESS AVE       2106020.0      36000.0    58.500556   \n",
       "133784         300 SUCCESS AVE       2106020.0      53000.0    39.736226   \n",
       "137339         300 SUCCESS AVE       2106020.0      51000.0    41.294510   \n",
       "139479     SUCCESS VLG BLDG 20       2106020.0      42000.0    50.143333   \n",
       "143481      SUCCESS VLG BLDG 5       2106020.0      15000.0   140.401333   \n",
       "143525         300 SUCCESS AVE       2106020.0      65000.0    32.400308   \n",
       "147082  SUCCESS VILLAGE 274-54       2106020.0      76000.0    27.710789   \n",
       "148982         300 SUCCESS AVE       2106020.0      41500.0    50.747470   \n",
       "149634                     NaN       2106020.0      45000.0    46.800444   \n",
       "153040         300 SUCCESS AVE       2106020.0      42000.0    50.143333   \n",
       "\n",
       "       property_type residential_type  \n",
       "129235           NaN              NaN  \n",
       "130650           NaN              NaN  \n",
       "131987           NaN              NaN  \n",
       "133784           NaN              NaN  \n",
       "137339           NaN              NaN  \n",
       "139479           NaN              NaN  \n",
       "143481           NaN              NaN  \n",
       "143525           NaN              NaN  \n",
       "147082           NaN              NaN  \n",
       "148982           NaN              NaN  \n",
       "149634           NaN              NaN  \n",
       "153040           NaN              NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice out all the rows where the town  and assesed_value is same as our first missing address\n",
    "raw_df[(raw_df['town'] == raw_df.loc[149634,\"town\"])&(raw_df['assessed_value']==raw_df.loc[149634,\"assessed_value\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that '300 Success Avenue' was put on the market several times. We can confirm this below by looking at the address with the most number of representation in this result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "address\n",
       "300 SUCCESS AVE           8\n",
       "SUCCESS VILLAGE 274-54    1\n",
       "SUCCESS VLG BLDG 20       1\n",
       "SUCCESS VLG BLDG 5        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the query, check the value counts \n",
    "raw_df[(raw_df['town'] == raw_df.loc[149634,\"town\"])&(raw_df['assessed_value']==raw_df.loc[149634,\"assessed_value\"])].value_counts('address')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that '300 SUCCESS AVE' has the most occurence here. We also know that the `assessed_value` matches as that was our filteration criteria. We can therefore impute this address for the first index in our missing list. Let's impute the address below with the one we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'300 SUCCESS AVE'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the address that has the most value counts with matching parameters\n",
    "raw_df[(raw_df['town'] == raw_df.loc[149634,\"town\"])&(raw_df['assessed_value']==raw_df.loc[149634,\"assessed_value\"])].value_counts('address').index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This address can be turned into a variable to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the address to impute as a variable\n",
    "address_imputer = raw_df[(raw_df['town'] == raw_df.loc[149634,\"town\"])&(raw_df['assessed_value']==raw_df.loc[149634,\"assessed_value\"])].value_counts('address').index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this variable to impute the first missing list index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the address with the value we found\n",
    "raw_df.loc[149634, [\"address\"]] = address_imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm this worked before moving on to other rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "serial_number                 10640\n",
       "list_year                      2001\n",
       "date_recorded            12/19/2001\n",
       "town                     Bridgeport\n",
       "address             300 SUCCESS AVE\n",
       "assessed_value            2106020.0\n",
       "sale_amount                 45000.0\n",
       "sales_ratio               46.800444\n",
       "property_type                   NaN\n",
       "residential_type                NaN\n",
       "Name: 149634, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check the index of the first row with missing address\n",
    "raw_df.loc[149634, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this worked, we can now remove the index from our `missing_address_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_address_list.remove(149634)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also continue with the remaining addresses down the list. Though, as this is a repeated procedure, we can create a function to undertake this search and extract the address that matches our values. One thing to keep in mind is that likely not all addresses will fit the search criteria of same `assessed_value`. So for these adddresses, we will have to look for the nearest assessed value within the same town. We can implement that in our function as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which takes in a name of town and and the assessed value \n",
    "def address_search(house_index):\n",
    "    \"\"\"\n",
    "    The function takes the index of the row with a missing address. It then finds the town and assessed_value \n",
    "    of this index. It creates a dataframe by using these 2 as filtering mechanisms.  \n",
    "\n",
    "    It counts the values of all the results and gives the address which has the\n",
    "    highest count. \n",
    "\n",
    "    If the exact assessed value is not found then the function searches wider\n",
    "    assessed_val by varying the range by a 1000$. \n",
    "\n",
    "    ----------------------------------------------------------------------------\n",
    "    INPUT:\n",
    "    index : int\n",
    "\n",
    "    OUTPUT:\n",
    "    Address of the highest count\n",
    "    \n",
    "    \"\"\"\n",
    "    # Assert that the index has to be a an integer\n",
    "    assert isinstance(house_index, int), \"Please use an integer as the index number\"\n",
    "\n",
    "    \n",
    "    location = raw_df.loc[house_index,:]\n",
    "    town = location[\"town\"]\n",
    "    assessed_val = location[\"assessed_value\"]\n",
    "   \n",
    "   \n",
    "    # Create a dataframe with the conditions given in the parameters\n",
    "    address_df =  raw_df[(raw_df['town'] == town)&(raw_df['assessed_value']==assessed_val)]\n",
    "\n",
    "    # If the number of rows in the DataFrame are more than 1\n",
    "    if len(address_df) > 1:\n",
    "        \n",
    "        # # (Uncomment to) Print the value counts of the addresses with given parameters \n",
    "        # print(address_df.value_counts('address'))\n",
    "\n",
    "        # Return the address with the most value counts\n",
    "        return address_df.value_counts('address').index[0]\n",
    "    \n",
    "    # If there are no results matching the paramters then\n",
    "    else:\n",
    "\n",
    "        # While there are no results showing under current parameters\n",
    "        while len(address_df) <= 1:\n",
    "\n",
    "            # # (Uncomment to) Print a statement for understanding process\n",
    "            # print(\"No exact assessed_value found, trying wider values...\")\n",
    "            \n",
    "            # Add an increasing upper and lower bound of assessed_value (+/-500) \n",
    "            lower_assessed = assessed_val - 500\n",
    "            higher_assessed = assessed_val + 500\n",
    "\n",
    "            # Check with new bounds of assessed_value to see if there are any addresses\n",
    "            address_df =  raw_df[(raw_df['town'] == town)&(raw_df['assessed_value'] > lower_assessed)&(raw_df['assessed_value'] < higher_assessed)]\n",
    "            \n",
    "            # # (Uncomment to) Print values\n",
    "            # print(address_df[[\"list_year\", \"address\", \"assessed_value\", \"sale_amount\"]])\n",
    "            # # (Uncomment to) Print return the most frequently obtained address\n",
    "            # print(address_df.value_counts('address'))\n",
    "            return address_df.value_counts('address').index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function can give us an address that is within the same town as the original index and has the closest assessed value. We can use the code below to impute the values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing index 263002 with 126 GUERNSEY LN\n",
      "Imputing index 284781 with OFF E CLARKS FLS\n",
      "Imputing index 310474 with 9 ROCKY RD\n",
      "Imputing index 330004 with 50 WINSHIP ST\n",
      "Imputing index 368444 with 1022 BUNKER HILL AVE\n",
      "Imputing index 372035 with 111 BECKLEY RD\n",
      "Imputing index 396820 with 180 FARMINGTON AVE\n",
      "Imputing index 471551 with 172 VALLEY VIEW RD\n",
      "Imputing index 471586 with BUELL RD\n",
      "Imputing index 480102 with 107 & 234 CARTER RD & 260 BROO\n",
      "Imputing index 499563 with 96 CINNAMON SPRINGS\n",
      "Imputing index 918890 with 101 CRESTWOOD DRIVE\n",
      "Imputing index 948235 with 11 LAUREL WOOD DR.\n",
      "Imputing index 952051 with 19 NORWAY ROAD\n"
     ]
    }
   ],
   "source": [
    "# For each index in the missing_address_list\n",
    "for ind in missing_address_list:\n",
    "\n",
    "    # Use the funciton to find the appropriate address\n",
    "    add = address_search(ind)\n",
    "\n",
    "    # Print the information for keeping track of it\n",
    "    print(f\"Imputing index {ind} with {add}\")\n",
    "\n",
    "    # Impute the missing address\n",
    "    raw_df.loc[ind,\"address\"] = add \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we can confirm that all missing addresses have been imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [serial_number, list_year, date_recorded, town, address, assessed_value, sale_amount, sales_ratio, property_type, residential_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing the dataframe and looking at the null values \n",
    "raw_df[raw_df['address'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now confirm that all addresses are imputed. We can also check other columns that may be having an issue with missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1054123 entries, 0 to 1054122\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   serial_number     1054123 non-null  int64  \n",
      " 1   list_year         1054123 non-null  int64  \n",
      " 2   date_recorded     1054123 non-null  object \n",
      " 3   town              1054123 non-null  object \n",
      " 4   address           1054123 non-null  object \n",
      " 5   assessed_value    1054123 non-null  float64\n",
      " 6   sale_amount       1054123 non-null  float64\n",
      " 7   sales_ratio       1054123 non-null  float64\n",
      " 8   property_type     671712 non-null   object \n",
      " 9   residential_type  660274 non-null   object \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 80.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Using the '.inf0()' to get the infromational snapshot\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 382411 missing rows of information in property_type\n",
      "There are 393849 missing rows of information in residential_type\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {raw_df['property_type'].isna().sum()} missing rows of information in property_type\")\n",
    "print(f\"There are {raw_df['residential_type'].isna().sum()} missing rows of information in residential_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore these further below, starting with `property_type`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining Missing Values for `property_type` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise a few of the rows where `property_type` is missing to ensure the correct information can be imputed (if possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>10095</td>\n",
       "      <td>2001</td>\n",
       "      <td>11/16/2001</td>\n",
       "      <td>Farmington</td>\n",
       "      <td>5 SPARROW LN</td>\n",
       "      <td>67670.0</td>\n",
       "      <td>302866.0</td>\n",
       "      <td>0.223432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>11238</td>\n",
       "      <td>2001</td>\n",
       "      <td>08/30/2002</td>\n",
       "      <td>Bethel</td>\n",
       "      <td>50 FOURTH ST</td>\n",
       "      <td>76450.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1.529000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10035</td>\n",
       "      <td>2001</td>\n",
       "      <td>06/28/2002</td>\n",
       "      <td>Chaplin</td>\n",
       "      <td>FEDERAL RD</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>10115</td>\n",
       "      <td>2001</td>\n",
       "      <td>02/01/2002</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>42 PRATT RD</td>\n",
       "      <td>121900.0</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10041</td>\n",
       "      <td>2001</td>\n",
       "      <td>07/17/2002</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>180.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    serial_number  list_year date_recorded        town       address  \\\n",
       "58          10095       2001    11/16/2001  Farmington  5 SPARROW LN   \n",
       "60          11238       2001    08/30/2002      Bethel  50 FOURTH ST   \n",
       "61          10035       2001    06/28/2002     Chaplin    FEDERAL RD   \n",
       "62          10115       2001    02/01/2002     Clinton   42 PRATT RD   \n",
       "71          10041       2001    07/17/2002    Eastford   WESTFORD RD   \n",
       "\n",
       "    assessed_value  sale_amount  sales_ratio property_type residential_type  \n",
       "58         67670.0     302866.0     0.223432           NaN              NaN  \n",
       "60         76450.0      50000.0     1.529000           NaN              NaN  \n",
       "61         19000.0      35000.0     0.542857           NaN              NaN  \n",
       "62        121900.0     230000.0     0.530000           NaN              NaN  \n",
       "71           180.0       5000.0     0.036000           NaN              NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[raw_df['property_type'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check some of these addresses in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10041</td>\n",
       "      <td>2001</td>\n",
       "      <td>07/17/2002</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>180.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>21002</td>\n",
       "      <td>2021</td>\n",
       "      <td>10/06/2021</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>20001</td>\n",
       "      <td>2020</td>\n",
       "      <td>10/13/2020</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>4110.0</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133262</th>\n",
       "      <td>10043</td>\n",
       "      <td>2001</td>\n",
       "      <td>07/17/2002</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134488</th>\n",
       "      <td>10042</td>\n",
       "      <td>2001</td>\n",
       "      <td>07/17/2002</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241612</th>\n",
       "      <td>30048</td>\n",
       "      <td>2003</td>\n",
       "      <td>08/10/2004</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655524</th>\n",
       "      <td>110005</td>\n",
       "      <td>2011</td>\n",
       "      <td>12/27/2011</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>4580.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>0.398261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810140</th>\n",
       "      <td>15019</td>\n",
       "      <td>2015</td>\n",
       "      <td>05/24/2016</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>29700.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034592</th>\n",
       "      <td>19034</td>\n",
       "      <td>2019</td>\n",
       "      <td>08/12/2020</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>5180.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         serial_number  list_year date_recorded      town      address  \\\n",
       "71               10041       2001    07/17/2002  Eastford  WESTFORD RD   \n",
       "1855             21002       2021    10/06/2021  Eastford  WESTFORD RD   \n",
       "6077             20001       2020    10/13/2020  Eastford  WESTFORD RD   \n",
       "133262           10043       2001    07/17/2002  Eastford  WESTFORD RD   \n",
       "134488           10042       2001    07/17/2002  Eastford  WESTFORD RD   \n",
       "241612           30048       2003    08/10/2004  Eastford  WESTFORD RD   \n",
       "655524          110005       2011    12/27/2011  Eastford  WESTFORD RD   \n",
       "810140           15019       2015    05/24/2016  Eastford  WESTFORD RD   \n",
       "1034592          19034       2019    08/12/2020  Eastford  WESTFORD RD   \n",
       "\n",
       "         assessed_value  sale_amount  sales_ratio property_type  \\\n",
       "71                180.0       5000.0     0.036000           NaN   \n",
       "1855             3390.0      40000.0     0.084700   Vacant Land   \n",
       "6077             4110.0     170000.0     0.024100   Vacant Land   \n",
       "133262            180.0       2500.0     0.072000           NaN   \n",
       "134488            180.0       2500.0     0.072000           NaN   \n",
       "241612              0.0      28000.0     0.000000           NaN   \n",
       "655524           4580.0      11500.0     0.398261           NaN   \n",
       "810140          29700.0      15000.0     1.980000           NaN   \n",
       "1034592          5180.0     125000.0     0.041400           NaN   \n",
       "\n",
       "        residential_type  \n",
       "71                   NaN  \n",
       "1855                 NaN  \n",
       "6077                 NaN  \n",
       "133262               NaN  \n",
       "134488               NaN  \n",
       "241612               NaN  \n",
       "655524               NaN  \n",
       "810140               NaN  \n",
       "1034592              NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[(raw_df['address'] == \"WESTFORD RD\") & (raw_df['town'] == \"Eastford\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that in the `town` of 'Eastford' in the `address` of 'WESTFORD RD', there are instances where the `property_type` are available as 'Vacant Land'. This could be used for imputation however the `sale_amount` is quite varied and the `address` lacks detail which means the imputation may be incorrect in this case. Therefore, we are deciding not to impute any of the `property_type`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining Missing Values for `residential_type` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`residential_type` is the last remaining column with missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1054123 entries, 0 to 1054122\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   serial_number     1054123 non-null  int64  \n",
      " 1   list_year         1054123 non-null  int64  \n",
      " 2   date_recorded     1054123 non-null  object \n",
      " 3   town              1054123 non-null  object \n",
      " 4   address           1054123 non-null  object \n",
      " 5   assessed_value    1054123 non-null  float64\n",
      " 6   sale_amount       1054123 non-null  float64\n",
      " 7   sales_ratio       1054123 non-null  float64\n",
      " 8   property_type     671712 non-null   object \n",
      " 9   residential_type  660274 non-null   object \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 80.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the ratio missing data in other columns\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These 393849 missing rows can be explored further.\n"
     ]
    }
   ],
   "source": [
    "print(f\"These {raw_df['residential_type'].isna().sum()} missing rows can be explored further.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>10095</td>\n",
       "      <td>2001</td>\n",
       "      <td>11/16/2001</td>\n",
       "      <td>Farmington</td>\n",
       "      <td>5 SPARROW LN</td>\n",
       "      <td>67670.0</td>\n",
       "      <td>302866.0</td>\n",
       "      <td>0.223432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>11238</td>\n",
       "      <td>2001</td>\n",
       "      <td>08/30/2002</td>\n",
       "      <td>Bethel</td>\n",
       "      <td>50 FOURTH ST</td>\n",
       "      <td>76450.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1.529000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10035</td>\n",
       "      <td>2001</td>\n",
       "      <td>06/28/2002</td>\n",
       "      <td>Chaplin</td>\n",
       "      <td>FEDERAL RD</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>10115</td>\n",
       "      <td>2001</td>\n",
       "      <td>02/01/2002</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>42 PRATT RD</td>\n",
       "      <td>121900.0</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10041</td>\n",
       "      <td>2001</td>\n",
       "      <td>07/17/2002</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>180.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    serial_number  list_year date_recorded        town       address  \\\n",
       "58          10095       2001    11/16/2001  Farmington  5 SPARROW LN   \n",
       "60          11238       2001    08/30/2002      Bethel  50 FOURTH ST   \n",
       "61          10035       2001    06/28/2002     Chaplin    FEDERAL RD   \n",
       "62          10115       2001    02/01/2002     Clinton   42 PRATT RD   \n",
       "71          10041       2001    07/17/2002    Eastford   WESTFORD RD   \n",
       "\n",
       "    assessed_value  sale_amount  sales_ratio property_type residential_type  \n",
       "58         67670.0     302866.0     0.223432           NaN              NaN  \n",
       "60         76450.0      50000.0     1.529000           NaN              NaN  \n",
       "61         19000.0      35000.0     0.542857           NaN              NaN  \n",
       "62        121900.0     230000.0     0.530000           NaN              NaN  \n",
       "71           180.0       5000.0     0.036000           NaN              NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_df[raw_df['residential_type'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check some of these addresses in more detail below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>10095</td>\n",
       "      <td>2001</td>\n",
       "      <td>11/16/2001</td>\n",
       "      <td>Farmington</td>\n",
       "      <td>5 SPARROW LN</td>\n",
       "      <td>67670.0</td>\n",
       "      <td>302866.0</td>\n",
       "      <td>0.223432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266137</th>\n",
       "      <td>30341</td>\n",
       "      <td>2003</td>\n",
       "      <td>04/16/2004</td>\n",
       "      <td>Farmington</td>\n",
       "      <td>5 SPARROW LN</td>\n",
       "      <td>205400.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0.513500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        serial_number  list_year date_recorded        town       address  \\\n",
       "58              10095       2001    11/16/2001  Farmington  5 SPARROW LN   \n",
       "266137          30341       2003    04/16/2004  Farmington  5 SPARROW LN   \n",
       "\n",
       "        assessed_value  sale_amount  sales_ratio property_type  \\\n",
       "58             67670.0     302866.0     0.223432           NaN   \n",
       "266137        205400.0     400000.0     0.513500           NaN   \n",
       "\n",
       "       residential_type  \n",
       "58                  NaN  \n",
       "266137              NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[(raw_df['address'] == \"5 SPARROW LN\") & (raw_df['town'] == \"Farmington\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>11238</td>\n",
       "      <td>2001</td>\n",
       "      <td>08/30/2002</td>\n",
       "      <td>Bethel</td>\n",
       "      <td>50 FOURTH ST</td>\n",
       "      <td>76450.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1.529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    serial_number  list_year date_recorded    town       address  \\\n",
       "60          11238       2001    08/30/2002  Bethel  50 FOURTH ST   \n",
       "\n",
       "    assessed_value  sale_amount  sales_ratio property_type residential_type  \n",
       "60         76450.0      50000.0        1.529           NaN              NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[(raw_df['address'] == \"50 FOURTH ST\") & (raw_df['town'] == \"Bethel\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10035</td>\n",
       "      <td>2001</td>\n",
       "      <td>06/28/2002</td>\n",
       "      <td>Chaplin</td>\n",
       "      <td>FEDERAL RD</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82131</th>\n",
       "      <td>21027</td>\n",
       "      <td>2021</td>\n",
       "      <td>06/01/2022</td>\n",
       "      <td>Chaplin</td>\n",
       "      <td>FEDERAL RD</td>\n",
       "      <td>20900.0</td>\n",
       "      <td>295000.0</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208323</th>\n",
       "      <td>20030</td>\n",
       "      <td>2002</td>\n",
       "      <td>06/23/2003</td>\n",
       "      <td>Chaplin</td>\n",
       "      <td>FEDERAL RD</td>\n",
       "      <td>156000.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        serial_number  list_year date_recorded     town     address  \\\n",
       "61              10035       2001    06/28/2002  Chaplin  FEDERAL RD   \n",
       "82131           21027       2021    06/01/2022  Chaplin  FEDERAL RD   \n",
       "208323          20030       2002    06/23/2003  Chaplin  FEDERAL RD   \n",
       "\n",
       "        assessed_value  sale_amount  sales_ratio property_type  \\\n",
       "61             19000.0      35000.0     0.542857           NaN   \n",
       "82131          20900.0     295000.0     0.070800   Vacant Land   \n",
       "208323        156000.0      40000.0     3.900000           NaN   \n",
       "\n",
       "       residential_type  \n",
       "61                  NaN  \n",
       "82131               NaN  \n",
       "208323              NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[(raw_df['address'] == \"FEDERAL RD\") & (raw_df['town'] == \"Chaplin\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>10115</td>\n",
       "      <td>2001</td>\n",
       "      <td>02/01/2002</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>42 PRATT RD</td>\n",
       "      <td>121900.0</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    serial_number  list_year date_recorded     town      address  \\\n",
       "62          10115       2001    02/01/2002  Clinton  42 PRATT RD   \n",
       "\n",
       "    assessed_value  sale_amount  sales_ratio property_type residential_type  \n",
       "62        121900.0     230000.0         0.53           NaN              NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[(raw_df['address'] == \"42 PRATT RD\") & (raw_df['town'] == \"Clinton\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>town</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "      <th>property_type</th>\n",
       "      <th>residential_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10041</td>\n",
       "      <td>2001</td>\n",
       "      <td>07/17/2002</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>180.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>21002</td>\n",
       "      <td>2021</td>\n",
       "      <td>10/06/2021</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>20001</td>\n",
       "      <td>2020</td>\n",
       "      <td>10/13/2020</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>4110.0</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>Vacant Land</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133262</th>\n",
       "      <td>10043</td>\n",
       "      <td>2001</td>\n",
       "      <td>07/17/2002</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134488</th>\n",
       "      <td>10042</td>\n",
       "      <td>2001</td>\n",
       "      <td>07/17/2002</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241612</th>\n",
       "      <td>30048</td>\n",
       "      <td>2003</td>\n",
       "      <td>08/10/2004</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655524</th>\n",
       "      <td>110005</td>\n",
       "      <td>2011</td>\n",
       "      <td>12/27/2011</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>4580.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>0.398261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810140</th>\n",
       "      <td>15019</td>\n",
       "      <td>2015</td>\n",
       "      <td>05/24/2016</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>29700.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034592</th>\n",
       "      <td>19034</td>\n",
       "      <td>2019</td>\n",
       "      <td>08/12/2020</td>\n",
       "      <td>Eastford</td>\n",
       "      <td>WESTFORD RD</td>\n",
       "      <td>5180.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         serial_number  list_year date_recorded      town      address  \\\n",
       "71               10041       2001    07/17/2002  Eastford  WESTFORD RD   \n",
       "1855             21002       2021    10/06/2021  Eastford  WESTFORD RD   \n",
       "6077             20001       2020    10/13/2020  Eastford  WESTFORD RD   \n",
       "133262           10043       2001    07/17/2002  Eastford  WESTFORD RD   \n",
       "134488           10042       2001    07/17/2002  Eastford  WESTFORD RD   \n",
       "241612           30048       2003    08/10/2004  Eastford  WESTFORD RD   \n",
       "655524          110005       2011    12/27/2011  Eastford  WESTFORD RD   \n",
       "810140           15019       2015    05/24/2016  Eastford  WESTFORD RD   \n",
       "1034592          19034       2019    08/12/2020  Eastford  WESTFORD RD   \n",
       "\n",
       "         assessed_value  sale_amount  sales_ratio property_type  \\\n",
       "71                180.0       5000.0     0.036000           NaN   \n",
       "1855             3390.0      40000.0     0.084700   Vacant Land   \n",
       "6077             4110.0     170000.0     0.024100   Vacant Land   \n",
       "133262            180.0       2500.0     0.072000           NaN   \n",
       "134488            180.0       2500.0     0.072000           NaN   \n",
       "241612              0.0      28000.0     0.000000           NaN   \n",
       "655524           4580.0      11500.0     0.398261           NaN   \n",
       "810140          29700.0      15000.0     1.980000           NaN   \n",
       "1034592          5180.0     125000.0     0.041400           NaN   \n",
       "\n",
       "        residential_type  \n",
       "71                   NaN  \n",
       "1855                 NaN  \n",
       "6077                 NaN  \n",
       "133262               NaN  \n",
       "134488               NaN  \n",
       "241612               NaN  \n",
       "655524               NaN  \n",
       "810140               NaN  \n",
       "1034592              NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[(raw_df['address'] == \"WESTFORD RD\") & (raw_df['town'] == \"Eastford\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `residential_type` seems to be missing even in multiple entries of the same address. This will make it difficult to impute. As `residential_type` is not important for this time series project. More time won't be spent trying to impute this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Saving the Current Dataset\n",
    "\n",
    "For now, we can save this version of the data as the addresses have been imputed. Thereafter, we can get the data further ready for the modelling aspect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data file \n",
    "raw_df.to_csv(\"data/Real_Estate_Sales_2001-2021_GL_Address_Imputed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now remove the unnecessary columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns which are not needed\n",
    "working_df = raw_df.drop(['serial_number', 'town', 'property_type', 'residential_type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_year</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>address</th>\n",
       "      <th>assessed_value</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sales_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>09/13/2021</td>\n",
       "      <td>230 WAKELEE AVE</td>\n",
       "      <td>150500.0</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>0.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>10/02/2020</td>\n",
       "      <td>390 TURNPIKE RD</td>\n",
       "      <td>253000.0</td>\n",
       "      <td>430000.0</td>\n",
       "      <td>0.588300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>07/05/2022</td>\n",
       "      <td>53 COTSWOLD WAY</td>\n",
       "      <td>329730.0</td>\n",
       "      <td>805000.0</td>\n",
       "      <td>0.409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>03/09/2021</td>\n",
       "      <td>5 CHESTNUT DRIVE</td>\n",
       "      <td>130400.0</td>\n",
       "      <td>179900.0</td>\n",
       "      <td>0.724800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>04/13/2021</td>\n",
       "      <td>111 NORTHINGTON DRIVE</td>\n",
       "      <td>619290.0</td>\n",
       "      <td>890000.0</td>\n",
       "      <td>0.695800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054118</th>\n",
       "      <td>2019</td>\n",
       "      <td>06/24/2020</td>\n",
       "      <td>4 BISHOP CT</td>\n",
       "      <td>60410.0</td>\n",
       "      <td>53100.0</td>\n",
       "      <td>1.137665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054119</th>\n",
       "      <td>2019</td>\n",
       "      <td>11/27/2019</td>\n",
       "      <td>126 PERKINS AVE</td>\n",
       "      <td>68280.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>0.898400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054120</th>\n",
       "      <td>2019</td>\n",
       "      <td>04/27/2020</td>\n",
       "      <td>19 HATHAWAY ST</td>\n",
       "      <td>121450.0</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>0.578300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054121</th>\n",
       "      <td>2019</td>\n",
       "      <td>06/03/2020</td>\n",
       "      <td>8 BYSTREK DR</td>\n",
       "      <td>203360.0</td>\n",
       "      <td>280000.0</td>\n",
       "      <td>0.726300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054122</th>\n",
       "      <td>2019</td>\n",
       "      <td>12/20/2019</td>\n",
       "      <td>250 RESEARCH DR</td>\n",
       "      <td>4035970.0</td>\n",
       "      <td>7450000.0</td>\n",
       "      <td>0.541700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1054123 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         list_year date_recorded                address  assessed_value  \\\n",
       "0             2020    09/13/2021        230 WAKELEE AVE        150500.0   \n",
       "1             2020    10/02/2020        390 TURNPIKE RD        253000.0   \n",
       "2             2021    07/05/2022        53 COTSWOLD WAY        329730.0   \n",
       "3             2020    03/09/2021       5 CHESTNUT DRIVE        130400.0   \n",
       "4             2020    04/13/2021  111 NORTHINGTON DRIVE        619290.0   \n",
       "...            ...           ...                    ...             ...   \n",
       "1054118       2019    06/24/2020            4 BISHOP CT         60410.0   \n",
       "1054119       2019    11/27/2019        126 PERKINS AVE         68280.0   \n",
       "1054120       2019    04/27/2020         19 HATHAWAY ST        121450.0   \n",
       "1054121       2019    06/03/2020           8 BYSTREK DR        203360.0   \n",
       "1054122       2019    12/20/2019        250 RESEARCH DR       4035970.0   \n",
       "\n",
       "         sale_amount  sales_ratio  \n",
       "0           325000.0     0.463000  \n",
       "1           430000.0     0.588300  \n",
       "2           805000.0     0.409600  \n",
       "3           179900.0     0.724800  \n",
       "4           890000.0     0.695800  \n",
       "...              ...          ...  \n",
       "1054118      53100.0     1.137665  \n",
       "1054119      76000.0     0.898400  \n",
       "1054120     210000.0     0.578300  \n",
       "1054121     280000.0     0.726300  \n",
       "1054122    7450000.0     0.541700  \n",
       "\n",
       "[1054123 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
